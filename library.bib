Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Unity2016,
author = {{Unity Technologies}},
title = {{Unity Personal}},
url = {https://store.unity.com/products/unity-personal},
urldate = {2017-01-11},
year = {2016}
}
@inproceedings{Nguyen2012,
abstract = {Bus is public means to travel in several cities. Traditional maps provide with the information of bus routes that passengers may use to design a travel from a place to another. It is difficult for them to obtain an appropriate route because of the lack of the information of time on the traditional maps. Some web sites enable passengers to take bus but they do not support passengers to have more diverse selections. In this paper, buses are considered as moving objects. Mathematically, movements of objects are the mappings (functions) from times to locations. In 3-D Cartesian coordinate systems, space-time cubes, which are called temporal maps in this paper, are models representing movements in spatio-temporal domain. A bus route on a traditional map is the curve connecting the spatial positions where the bus visits, from the departure station to the arrival. A bus trip is a bus route included time. It is represented on temporal maps. With the visualization of spatio-temporal data of bus trips on temporal maps, passengers may mark out bus trips for their more appropriate travels. This article implemented visualization tools for the design of bus travels on temporal maps.},
author = {Nguyen, Hong Thi and Duong, Chi Kim Thi and Bui, Tha Thi and Tran, Phuoc Vinh},
booktitle = {2012 International Conference on Control, Automation and Information Sciences, ICCAIS 2012},
doi = {10.1109/ICCAIS.2012.6466625},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Nguyen et al/2012 International Conference on Control, Automation and Information Sciences, ICCAIS 2012/Visualization of spatio-temporal data of bus trips.pdf:pdf},
isbn = {9781467308137},
pages = {392--397},
title = {{Visualization of Spatio-temporal Data of Bus Trips}},
year = {2012}
}
@inproceedings{Craft2005,
abstract = {The field of information visualization offers little methodological guidance to practitioners who seek to design novel systems. Though many sources describe the foundations of the domain, few discuss practical methods for solving visualization problems. One frequently cited guideline to design is the "Visual information-seeking mantra", proposed by Shneiderman in 1996. Although often used to inform the design of information visualization systems, it is unclear what use this has been for visualization designers. We reviewed the current literature that references the mantra, noting what authors have found useful about it and why they cite it. The results indicate a need for empirical validation of the mantra and for a method, such as design patterns, to inform a holistic approach to visualisation design.},
author = {Craft, Brock and Cairns, Paul},
booktitle = {Proceedings of the Ninth International Conference on Information Visualisation},
doi = {10.1109/IV.2005.28},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Craft, Cairns/Proceedings of the Ninth International Conference on Information Visualisation/Craft, Cairns - 2005 - Beyond Guidelines What Can We Learn from the Visual Information Seeking Mantra.pdf:pdf},
isbn = {0769523978},
issn = {10939547},
keywords = {Guidelines,Patterns,Visual information seeking mantra,Visualization methodology},
pages = {110--118},
title = {{Beyond Guidelines: What Can We Learn from the Visual Information Seeking Mantra?}},
year = {2005}
}
@misc{Microsoft2010,
author = {Microsoft},
title = {{‘Kinect for Xbox 360' is Official Name of Microsoft's Controller-Free Game Device}},
url = {https://news.microsoft.com/2010/06/13/kinect-for-xbox-360-is-official-name-of-microsofts-controller-free-game-device/},
urldate = {2016-04-13},
year = {2010}
}
@book{Rosson2002,
abstract = {You don't need to be convinced. You know that usability is key to the success of any interactive system-from commercial software to B2B Web sites to handheld devices. But you need skills to make usability part of your product development equation. How will you assess your users' needs and preferences? How will you design effective solutions that are grounded in users' current practices? How will you evaluate and refine these designs to ensure a quality product?Usability Engineering: Scenario-Based Development of Human-Computer Interaction is a radical departure from traditional books that emphasize theory and address experts. This book focuses on the realities of product development, showing how user interaction scenarios can make usability practices an integral part of interactive system development. As you'll learn, usability engineering is not the application of inflexible rules; it's a process of analysis, prototyping, and problem solving in which you evaluate tradeoffs, make reasoned decisions, and maximize the overall value of your product. * Written by prominent HCI educators who understand how to teach usability practices to students and professional developers.* Interleaves HCI theory and concepts with a running case study demonstrating their application. * Gradually elaborates the case study to introduce increasingly sophisticated usability engineering techniques.* Analyzes usability issues in realistic scenarios that describe existing or envisioned systems from the perspective of one or more users.* Emphasizes the real world of usability engineering-a world in which tradeoffs must be weighed and difficult decisions made to achieve desired results.* Includes a companion Web site which provides additional case studies in a multimedia format, along with a Java application for creating and editing scenarios. This site also provides instructors with sample syllabi, lecture slides and notes, in-class exercises, solutions to textbook exercises, additional project ideas, and links to other HCI resources.},
author = {Rosson, Mary Beth and Carroll, John Millar},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Rosson, Carroll/Unknown/Rosson, Carroll - 2002 - Usability Engineering Scenario-based Development of Human-computer Interaction.pdf:pdf},
isbn = {1558607129},
pages = {422},
publisher = {Morgan Kaufmann},
title = {{Usability Engineering: Scenario-based Development of Human-computer Interaction}},
year = {2002}
}
@article{Stephens2004,
abstract = {Knowledge discovery and visualisation are important techniques for discovering and understanding patterns in large data sets. The study presents the development of a three dimensional virtual reality model that assists the user to visually explore structures and relationships in the collected data. The three dimensional model uses a combination of nodes and paths to represent objects/actors and the strength/direction of the measured characteristic. Virtual reality provides the mechanism for manipulation of the developed model in real time. Specifically, we demonstrate the potential of this visual tool by having postgraduate students, organised into focus groups, engage in a knowledge discovery exercise with data collected in an academic work environment. The method adopted to convert the identified relationships into a virtual reality model is discussed, as well as some of the additional features that could be incorporated using such a method.},
author = {Stephens, G. and Handzic, M.},
doi = {10.1109/HICSS.2004.1265586},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Stephens, Handzic/37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the/Knowledge discovery through visualising using virtual reality.pdf:pdf},
isbn = {0-7695-2056-1},
journal = {37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the},
number = {C},
pages = {1--10},
title = {{Knowledge Discovery Through Visualising Using Virtual Reality}},
volume = {00},
year = {2004}
}
@article{Bowman1998,
abstract = {We present a virtual environment application that allows users to access embedded information within an immersive virtual space. Due to the richness and complexity of this environment, efficient and easy-to-use interaction techniques are a crucial requirement. The “Virtual Venue” seamlessly combines both twoand three-dimensional interaction techniques into a single system and utilizes previously reported as well as novel techniques that fit the task of information access. We present tools for user control of the system, travel through the environment, and information retrieval, as well as authoring tools for the creation of information-rich virtual environments. A usability study and its results are also presented and discussed. The study indicates that the use of abstract information that is tightly coupled to the virtual environment can be quite successful in enhancing the relevance of both the environment and the information. Results also show that the set of well-constrained interaction techniques presented here are usable and efficient for information retrieval.},
author = {Bowman, Doug A. and Hodges, Larry F. and Bolter, Jay},
doi = {10.1162/105474698565866},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Bowman, Hodges, Bolter/Presence Teleoperators and Virtual Environments/Bowman, Hodges, Bolter - 1998 - The Virtual Venue User-Computer Interaction in Information-Rich Virtual Environments.pdf:pdf},
isbn = {10.1162/105474698565866},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
keywords = {animation,human-computer interaction,information,introduction and related work,virtual reality,visualization},
number = {5},
pages = {478--493},
title = {{The Virtual Venue: User-Computer Interaction in Information-Rich Virtual Environments}},
url = {http://dx.doi.org/10.1162/105474698565866{\%}5Cnhttp://www.mitpressjournals.org/doi/abs/10.1162/105474698565866},
volume = {7},
year = {1998}
}
@inproceedings{Ware1994,
abstract = {An experiment is reported which tests whether network information is more effectively displayed in a three dimensional space than in a two dimensional space. The experimental task is to trace a path in a network and the experiment is carried out in 2D, in a 3D stereo view, in a 2D view with head coupled perspective, and in a 3D stereo view with head coupled perspective; this last condition creates a localized virtual reality display. The results show that the motion parallax obtained from the head coupling of perspective is more important than stereopsis in revealing structural information. Overall the results show that three times as much information can be perceived in the head coupled stereo view as in the 2D view},
author = {Ware, Colin and Franck, Glenn},
booktitle = {Proceedings of 1994 IEEE Symposium on Visual Languages},
doi = {10.1109/VL.1994.363621},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ware, Franck/Proceedings of 1994 IEEE Symposium on Visual Languages/Viewing a graph in a virtual reality display is three times as good as a 2D diagram.pdf:pdf},
isbn = {0-8186-6660-9},
issn = {10492615},
keywords = {2D diagram,2D view,3D stereo view,Computer displays,Eyes,Glass,Head,Layout,Orthopedic surgery,Testing,Three dimensional displays,Two dimensional displays,Virtual reality,motion parallax,network information,stereopsis,structural information,virtual reality,virtual reality display,visual languages,visual perception},
pages = {182--183},
publisher = {IEEE},
title = {{Viewing a Graph in a Virtual Reality Display is Three Times as Good as a 2D Diagram}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=363621},
year = {1994}
}
@inproceedings{Valve2016,
abstract = {When we noticed that most VR developers were using Unity, we decided to use it ourselves. This meant that as we encountered and solved problems, we could share those solutions with Unity's VR development community. In this session we will look at some upcoming VR-focused features developed by Valve for use in Unity. This includes built-in SteamVR support in Unity aimed at simplifying multiplatform development and a high-performance rendering plugin to help you hit 90 FPS without sacrificing visual quality.},
address = {Hollywood, CA},
author = {{Valve Corporation}},
booktitle = {Vision VR/AR Summit 2016},
title = {{Using Unity at Valve}},
url = {https://www.youtube.com/watch?v=4Gs5k2Fti1U},
year = {2016}
}
@inproceedings{Kunzle2015,
abstract = {This paper describes how a Virtual Bank - a development and testing environment based on a purely synthetic test data base - has been established to address the challenge of protecting sensitive business and client data, while at the same time collaborating in application development and testing across country and jurisdiction borders.},
author = {Kunzle, Daniel and Worms, Carl},
booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
doi = {10.1109/ICST.2015.7102620},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Kunzle, Worms/2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)/Kunzle, Worms - 2015 - A Virtual Bank for Development and Testing.pdf:pdf},
isbn = {978-1-4799-7125-1},
keywords = {Business,Data privacy,Information technology,Production systems,Servers,Testing,Virtual Bank,application development,application testing,business data processing,client data protection,data protection,development environment,program testing,programming environments,purely synthetic test database,security of data,sensitive business protecting,testing environment},
month = {apr},
pages = {1--2},
publisher = {IEEE},
shorttitle = {Software Testing, Verification and Validation (ICS},
title = {{A Virtual Bank for Development and Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7102620},
year = {2015}
}
@misc{LeapMotion2016,
author = {{Leap Motion}},
title = {{Geometric}},
url = {https://gallery.leapmotion.com/geometric/},
urldate = {2017-01-06},
year = {2016}
}
@inproceedings{Latham1997,
abstract = {Issues related to the design of virtual reality systems are discussed in the context of the development effort for a virtual cockpit. Subsystems provide visual imagery, hand and head tracking, control logic and force feedback. The force feedback subsystem uses robotic positioning to place an assortment of knobs and switches into position to be touched: the user's hand trajectory is extrapolated and the correct type of control is placed just in time to be actuated. Discussion focuses on selecting among alternative system elements and configurations in arriving at an overall systems design.},
author = {Latham, R.},
booktitle = {Proceedings IEEE COMPCON 97. Digest of Papers},
doi = {10.1109/CMPCON.1997.584738},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Latham/Proceedings IEEE COMPCON 97. Digest of Papers/Latham - 1997 - Designing virtual reality systems a case study of a system with humanrobotic interaction.pdf:pdf},
isbn = {0-8186-7804-6},
issn = {1063-6390},
keywords = {Aircraft manufacture,Computational modeling,Computer aided software engineering,Computer displays,Force control,Human robot interaction,Image generation,Instruments,Switches,Virtual reality,actuation,aircraft computers,case study,control logic,feedback,force feedback,hand tracking,hand trajectory extrapolation,head tracking,human/robotic interaction,interactive devices,knobs,man-machine systems,robotic positioning,robots,subsystems,switches,system configurations,system elements,tracking,virtual cockpit,virtual reality,virtual reality systems design,visual imagery},
pages = {302--307},
publisher = {IEEE Comput. Soc. Press},
shorttitle = {Compcon '97. Proceedings, IEEE},
title = {{Designing Virtual Reality Systems: A Case Study of a System with Human/Robotic Interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=584738},
year = {1997}
}
@article{Dash2002,
abstract = {In this paper, we address the problem of automatic camera positioning and automatic camera path generation in the context of historical data visualization. After short description of the given data, we elaborate on the constraints for the positioning of a virtual camera in such a way that not only the projected area is maximized, but also the depth of the displayed scene. This is especially important when displaying terrain models, which do not provide good 3D impression when only the projected area is maximized. Based on this concept, we present a method for computing an optimal camera position for each instant of time. Since the explored data are not static, but change depending on the explored scene time, we also discuss a method for animation generation. In order to avoid sudden changes of the camera position, when the previous method is applied for each frame (point in time), we introduce pseudo-events in time, which expand the bounding box defined by the currently active events of interest. In particular, this technique allows events happening in a future point in time to be taken into account such that when this time becomes current, all events of interest are already within the current viewing frustum of the camera.},
author = {Dash, Puja},
doi = {10.1109/VISUAL.2002.1183826},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Dash/IEEE Visualization, 2002. VIS 2002/Dash - 2002 - A case study on automatic camera placement and motion for visualizing historical data.pdf:pdf},
isbn = {0-7803-7498-3},
issn = {0780374983},
journal = {IEEE Visualization, 2002. VIS 2002.},
keywords = {automatic camera control,automatic camera path and,data,fly control generator turned,historical,out to be,time-dependent data,very useful exploration props,visualization,visualization techniques},
number = {49},
pages = {545--548},
title = {{A Case Study on Automatic Camera Placement and Motion for Visualizing Historical Data}},
year = {2002}
}
@article{Li2005a,
abstract = {Virtual banking is broadly defined in this paper as the provision of banking services via means other than that of traditional physical branches. Currently, virtual banking exists in the forms of ATM, phone banking, home banking and Internet banking. Understanding people's adoption intention of virtual banking can help financial institutions formulate appropriate marketing strategies for new forms of banking. This paper examines the current trends in the Internet revolution that have set in motion in the Chinese banking sector, and reports on an empirical research carried out in China to study the customers' preference for virtual banking and the factors which they consider influence the adoption of virtual banking.},
author = {Li, Zheng and Zhong, Yonghong},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Li, Zhong/Chinese Business Review/Li, Zhong - 2005 - The Adoption of Virtual Banking in China An Empirical Study.pdf:pdf},
journal = {Chinese Business Review},
keywords = {Information technology,commercial bank,virtual banking},
number = {3},
pages = {75--78},
title = {{The Adoption of Virtual Banking in China: An Empirical Study}},
url = {http://tpprofiuba.googlecode.com/svn-history/r195/trunk/Material/e-Banking/17-The Adoption of Virtual Banking in.pdf},
volume = {1},
year = {2005}
}
@book{Ware2012,
abstract = {Most designers know that yellow text presented against a blue background reads clearly and easily, but how many can explain why, and what really are the best ways to help others and ourselves clearly see key patterns in a bunch of data? This book explores the art and science of why we see objects the way we do. Based on the science of perception and vision, the author presents the key principles at work for a wide range of applications-resulting in visualization of improved clarity, utility, and persuasiveness. The book offers practical guidelines that can be applied by anyone: interaction designers, graphic designers of all kinds (including web designers), data miners, and financial analysts.First work to use the science of perception to help serious designers and analysts optimize understanding and perception of their data visualizations. Major revision of this classic work, with a new chapter on visual thinking, new sections on face perception and flow visualization, and a much expanded chapter on color and color sequences. New to this edition is the full color treatment throughout, to better display over 400 illustrations.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Ware, Colin},
booktitle = {Information Visualization},
doi = {0-12-381464-2, 978-0-12-381464-7},
edition = {3},
eprint = {9809069v1},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ware/Information Visualization/Ware - 2012 - Information Visualization Perception for Design.pdf:pdf},
isbn = {978-0-12-381464-7},
issn = {1471-2105},
pages = {536},
pmid = {13407295},
primaryClass = {arXiv:gr-qc},
publisher = {Elsevier Inc.},
title = {{Information Visualization: Perception for Design}},
url = {https://books.google.ch/books?id=UpYCSS6snnAC},
year = {2012}
}
@inproceedings{Ahlberg1994,
author = {Ahlberg, Christopher and Shneiderman, Ben},
booktitle = {CHI '94 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/191666.191775},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ahlberg, Shneiderman/CHI '94 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems/Ahlberg, Shneiderman - 1994 - Visual Information Seeking Tight Coupling of Dynamic Query Filters with S.pdf:pdf},
isbn = {0-89791-650-6},
keywords = {and ben shneiderrnan,christopher a hlberg,query filters,tight coupling of dynamic,ual information seeking,with starfield displays},
pages = {313--317},
title = {{Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays}},
year = {1994}
}
@book{Adapa2011,
abstract = {The traditional mode of delivering products and services by banks to the consumers' is through a single distribution channel and that is physical bank branches. Financial services industry is metamorphosing due to the advent of internet, rapid technological evolutions, deregulation, globalization as well as the impact of changing competitive and regulatory forces. In order to cope with the quick changes in the business scenario, banks started to rely on distribution channels as an alternative strategy for differentiation and gaining further competitive advantage. The abovementioned paved way for the development of the ebanking phenomena. This chapter attempts to provide a comprehensive explanation of what ebanking is, the evolution of ebanking, existing trends of ebanking in developed, developing and newly industrialized nations, future directions for further possible research and concluding remarks. The content provided in this chapter would be useful for existing and potential banks to better understand the global ebanking trends and thus aid in the effective formulation of channel management strategies and reap the benefits out of it.},
author = {Adapa, Sujana},
booktitle = {E-Banking and Emerging Multidisciplinary Processes},
doi = {10.4018/978-1-61520-635-3.ch001},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Adapa/E-Banking and Emerging Multidisciplinary Processes/Adapa - 2011 - Global E-Banking Trends Evolution, Challenges and Opportunities.pdf:pdf},
isbn = {9781615206353},
pages = {1--16},
publisher = {IGI Global},
title = {{Global E-Banking Trends: Evolution, Challenges and Opportunities}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-635-3.ch001},
year = {2011}
}
@article{Sun2011,
abstract = {The study constructs joyful Web 3D virtual situational learning materials with the perspectives of learners, and takes Tainan Confucian Temple as an example to allow the learners to learn and experience freely in virtual reality. The joyful learning environment is presented in the virtual situation through vivid text, sound, a guided picture tour, and a game-like learning mechanism. Different from the passive “knowledge giving model” in the past virtual situational learning system, the “joyful learning component” is integrated into the virtual situation to change knowledge imparting from “passive” to “active” to effectively enhance the learning motivation of learners and improve their learning effectiveness. Finally, grade 5 students are applied as the experimental subjects in the study analysis focusing on the satisfaction of learning system application and the significance difference of the learning result before and after the system is applied. The study result shows that the application of a joyful virtual situation can indeed achieve the same effectiveness of on- site experimental learning.},
author = {Sun, Koun-Tem and Chan, Hsin-Te and Yin, Tai-lin},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Sun, Chan, Yin/The 7th International Conference on Digital Content, Multimedia Technology and its Applications/Sun, Chan, Yin - 2011 - A case study on building Web3D virtual reality and its applications to j.pdf:pdf},
isbn = {9788988678466},
journal = {The 7th International Conference on Digital Content, Multimedia Technology and its Applications},
keywords = {Electronic learning,Games,Learning systems,Solid modeling,Tainan Confucian Temple,Three dimensional displays,Web3D virtual reality building,computer aided instruction,e-learning,game-like learning mechanism,joyful Web 3D virtual situational learning materia,joyful learning component,knowledge giving model,learning,on-site experimental learning,situational teaching,virtual reality,virtual situational learning system},
mendeley-tags = {e-learning,learning,situational teaching},
month = {aug},
pages = {49--54},
title = {{A Case Study on Building Web3D Virtual Reality and Its Applications to Joyful Learning}},
url = {http://ieeexplore.ieee.org/ielx5/6008798/6016618/06016630.pdf?tp={\&}arnumber=6016630{\&}isnumber=6016618},
year = {2011}
}
@article{Sarathy2000,
abstract = {Major advances in high performance computing software and hardware$\backslash$nhave made it possible for designers and analysts to obtain detailed$\backslash$ninformation about the behavior of complex systems. However, this has$\backslash$nlead to a proliferation of vast amounts of data which is beyond the$\backslash$nability of humans to easily comprehend using traditional visualization$\backslash$nmethods. The method presented combines emerging visualization tools with$\backslash$ndata filtering and data mining techniques. This method uses virtual$\backslash$nreality (VR) coupled with multimedia techniques to display information$\backslash$nwithin an environment that allows non-expert users to understand and$\backslash$ninterpret the data. A prototype visualization tool was developed under a$\backslash$nNASA SBIR Phase II effort. This paper builds on the results of this work$\backslash$nand suggests a visualization framework that can be used to examine,$\backslash$ncomprehend and interpret results in any complex data set, particularly$\backslash$nthose used in support of decision making activities},
author = {Sarathy, S. and Shujaee, K. and Cannon, K.},
doi = {10.1109/ITCC.2000.844280},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Sarathy, Shujaee, Cannon/Proceedings International Conference on Information Technology Coding and Computing (Cat. No.PR00540)/Visualization of large complex datasets using virtual reality.pdf:pdf},
isbn = {0-7695-0540-6},
journal = {Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540)},
pages = {1--5},
title = {{Visualization of Large Complex Datasets using Virtual Reality}},
year = {2000}
}
@misc{Google2016a,
author = {Google},
booktitle = {Steam},
title = {{Google Earth VR}},
url = {http://store.steampowered.com/app/348250/},
urldate = {2016-12-10},
year = {2016}
}
@inproceedings{Chun2015,
abstract = {The computers nowadays are powerful enough to make the virtual reality technology more practical. Virtual reality is expected to have a bright future due to the rise of several virtual reality head mounted device such as low cost Google Cardboard, Samsung Gear VR, Oculus, HTC Vive and many others. Since virtual reality had been growing fast in this few years thus it is necessary to explore new approaches for user to interact with the virtual reality more naturally. It is an important research in HCI to make the interactions with computers to be as natural as the interaction between humans. One of the approaches is to allow user to interact with the virtual reality through gesture and speech input. This paper presents a virtual reality environment with multimodal interaction technique. It allows user to interact with the virtual reality system with the static and stroke hand gesture along with speech. This multimodal interaction technique is able to perform few functions such as select, move, scale, rotate, copy, mirror, delete, check the shape, check and change the colour of an object.},
author = {Chun, Lam Meng and Arshad, Haslina and Piumsomboon, Thammathip and Billinghurst, Mark},
booktitle = {2015 International Conference on Electrical Engineering and Informatics (ICEEI)},
doi = {10.1109/ICEEI.2015.7352470},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Chun et al/2015 International Conference on Electrical Engineering and Informatics (ICEEI)/Chun et al. - 2015 - A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual.pdf:pdf},
isbn = {9781467373197},
keywords = {Virtual Reality,gesture,hand gesture and speech,human computer interaction,interaction,multimodal,natural interaction,new,speech,speech recognition},
mendeley-tags = {Virtual Reality,gesture,multimodal,new,speech,speech recognition},
month = {aug},
pages = {59--64},
publisher = {IEEE},
title = {{A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=7352470},
year = {2015}
}
@inproceedings{Shujun2011,
abstract = {Mixed reality (MR) is a further research hotspot with the development of virtual reality (VR). Seamless fusion and real-time interaction between virtual environment and real users or objects are two most important problems urgent to be solved for a MR system. In this paper an engine of virtual reality mixing environment E-VRME is proposed based on real-time modeling and interaction and three applications are demonstrated. The engine runs on our self-built hardware platform DreamWorld and has three modules. Graphics module is designed for VE rendering, modeling module for 3D reconstruction and V-R interaction module for collision detection and feedback. An octree-based visual hull modeling method is used for constructing the mesh models of all the users from their multi-view images. Then, marching cubes algorithm is applied for triangulation and texture mapping is carried out. E-VRME integrates virtual and real information into a seamless unit and it supports any kinds of real-time MR applications. Experimental results and three different application systems proved its usefulness and effectiveness.},
author = {Shujun, Zhang},
booktitle = {2011 IEEE International Symposium on VR Innovation},
doi = {10.1109/ISVRI.2011.5759621},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Shujun/2011 IEEE International Symposium on VR Innovation/Shujun - 2011 - An engine of virtual reality mixing environment based on real-time modeling and interaction.pdf:pdf},
isbn = {978-1-4577-0055-2},
keywords = {Cameras,DreamWorld,E-VRME,Engines,Image reconstruction,MR,Mixed reality,Real time systems,Solid modeling,VE rendering,Virtual reality,Visualization,collision detection,computer graphics,engine of virtual reality mixing environment,graphics module,mixed reality,real time reconstruction,real-time interaction,real-time modeling,real-time systems,tele-immersion,virtual reality,virtual-reality interaction},
month = {mar},
pages = {155--159},
publisher = {IEEE},
shorttitle = {VR Innovation (ISVRI), 2011 IEEE International Sym},
title = {{An Engine of Virtual Reality Mixing Environment Based on Real-Time Modeling and Interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5759621},
year = {2011}
}
@article{Forsberg1997,
abstract = {Jot is a novel research interface for virtual reality modeling. This system seamlessly integrates and applies a variety of virtual and physical tools, each customized for specific tasks. The Jot interface not only moves smoothly from one tool to another but also physically and cognitively matches individual tools to the tasks they perform. In particular, we exploit the notion that gestural interaction is more direct, in many cases, than traditional widget based interaction. We also respect the time tested observation that some operations-even conceptually three dimensional ones-are better performed with 1D or 2D input devices, whereas other operations are more naturally performed using stereoscopic views, higher DOF input devices, or both. Ultimately we strive for a 3D modeling system with an interface as transparent as the interaction afforded by a pencil and a sheet of paper. For example, the system should facilitate the tasks of drawing and erasing and provide an easy transition between the two. Jot emerged from our previous work on a mouse based system, called Sketch, for gesturally creating imprecise 3D models. Jot extends Sketch's functionality to a wider spectrum of modeling, from concept design to detailed feature based parametric parts. Jot also extends the interaction in Sketch to better support individual modeling tasks. We extended Sketch's gestural framework to integrate interface components ranging from traditional desktop interface widgets to context sensitive gestures to direct manipulation techniques originally designed for immersive VR},
author = {Forsberg, A.S. and LaViola, J.J. and Markosian, L. and Zeleznik, R.C.},
doi = {10.1109/38.626956},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Forsberg et al/IEEE Computer Graphics and Applications/Forsberg et al. - 1997 - Seamless interaction in virtual reality.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
keywords = {3D modeling system,CAD,Geometry,Graphics,Java,Jot interface,Sketch,Surface fitting,Switches,Testing,Topology,Virtual reality,Web sites,Wheels,cognitive matching,concept design,context sensitive gestures,design engineering,desktop interface widgets,detailed feature based parametric parts,direct manipulation techniques,drawing,engineering graphics,erasing,gestural framework,gestural interaction,graphical user interfaces,immersive VR,imprecise 3D models,individual modeling tasks,interactive systems,mouse based system,novel research interface,seamless interaction,stereoscopic views,virtual reality,virtual reality modeling,widget based interaction},
number = {6},
pages = {6--9},
shorttitle = {IEEE Computer Graphics and Applications},
title = {{Seamless Interaction in Virtual Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=626956},
volume = {17},
year = {1997}
}
@inproceedings{Rautaray2011,
abstract = {Hand gesture recognition systems for virtual reality applications provides the users an enhanced interaction experience as it integrates the virtual and the real world object. Growth in virtual environments based upon computer systems and development of user interfaces influence the changes in the Human-Computer Interaction (HCI). Gesture recognition based interaction interface, endow with more realistic and immersive interaction compared to the traditional devices. The system enables a physically realistic mode of interaction to the virtual environment. The Hand gesture recognition system based interface proposed and implemented in this paper consists of a detection, tracking and recognition module. For the implementation of these modules various image processing algorithms as Camshift, Lucas Kanade, Haar like features etc has been employed. Comprehensive user acceptability has been considered to exhibit the accuracy, usefulness and ease of use to the proposed and implemented hand gesture recognition system. Hand gesture communication based vocabulary offers many variations ranging from simple action of using our finger to point at to using hands for moving objects around to the rather complex one like expression of the feelings. The proposed hand gesture recognition system offers intensions to traditional input devices for interaction with the virtual environments. The gesture based interaction interface being proposed here can be substantially applied towards many applications like Virtual Reality, Sign Language and Games. Though the present paper considered games as the application domain.},
author = {Rautaray, Siddharth S. and Agrawal, Anupam},
booktitle = {2011 International Conference on Multimedia, Signal Processing and Communication Technologies},
doi = {10.1109/MSPCT.2011.6150485},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Rautaray, Agrawal/2011 International Conference on Multimedia, Signal Processing and Communication Technologies/Rautaray, Agrawal - 2011 - Interaction with virtual game through hand gesture recognition.pdf:pdf},
isbn = {978-1-4577-1107-7},
keywords = {Camshift image processing algorithms,Games,Gesture recognition,Haar like features,Human computer interaction,Humans,Lucas Kanade image processing algorithms,Multimedia communication,Tracking,Virtual environments,computer games,computer systems,gesture recognition,gesture recognition based interaction interface,hand gesture communication based vocabulary,hand gesture recognition systems,human computer interaction,human-computer interaction,palmprint recognition,sign language,user interfaces,virtual game,virtual reality},
month = {dec},
pages = {244--247},
publisher = {IEEE},
shorttitle = {Multimedia, Signal Processing and Communication Te},
title = {{Interaction with Virtual Game through Hand Gesture Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6150485},
year = {2011}
}
@book{Bunt1998,
author = {Bunt, Harry and Beun, Robbert-Jan and Borghuis, Tijn},
edition = {1},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Bunt, Beun, Borghuis/Unknown/Bunt, Beun, Borghuis - 1998 - Multimodal Human-Computer Communication Systems, Techniques, and Experiments.pdf:pdf},
isbn = {3-540-64380-X},
pages = {349},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Multimodal Human-Computer Communication: Systems, Techniques, and Experiments}},
year = {1998}
}
@article{Cao2009,
abstract = {The paper attempts to focus on application method of virtual reality and take advantage of cognitive feature of virtual interface to explore animation interaction design. It aims at supplying feasible methods to realize simulation function of virtual reality and integrate the techniques required for creating digital actors and improve cognitive ability of human-machine interaction. This article describes motion technique and dynamic simulation of digital actor in animation area, and explores the problems and solutions including virtual animation in immersive virtual environments so as to validate the results of research on these topics.},
author = {Cao, Yali},
doi = {10.1109/CAIDCD.2009.5375379},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Cao/IEEE 10th International Conference on Computer-Aided Industrial Design {\&} Conceptual Design, 2009. CAID {\&} CD 2009/Cao - 2009 - Research on Interaction Design of Virtual Reality.pdf:pdf},
isbn = {9781424452682},
journal = {IEEE 10th International Conference on Computer-Aided Industrial Design {\&} Conceptual Design, 2009. CAID {\&} CD 2009.},
pages = {1340--1344},
title = {{Research on Interaction Design of Virtual Reality}},
year = {2009}
}
@article{Donalek2014,
abstract = {Effective data visualization is a key part of the discovery process in the era of “big data”. It is the bridge between the quantitative content of the data and human intuition, and thus an essential component of the scientific path from data into knowledge and understanding. Visualization is also essential in the data mining process, directing the choice of the applicable algorithms, and in helping to identify and remove bad data from the analysis. However, a high complexity or a high dimensionality of modern data sets represents a critical obstacle. How do we visualize interesting structures and patterns that may exist in hyper-dimensional data spaces? A better understanding of how we can perceive and interact with multidimensional information poses some deep questions in the field of cognition technology and human-computer interaction. To this effect, we are exploring the use of immersive virtual reality platforms for scientific data visualization, both as software and inexpensive commodity hardware. These potentially powerful and innovative tools for multi-dimensional data visualization can also provide an easy and natural path to a collaborative data visualization and exploration, where scientists can interact with their data and their colleagues in the same visual space. Immersion provides benefits beyond the traditional “desktop” visualization tools: it leads to a demonstrably better perception of a datascape geometry, more intuitive data understanding, and a better retention of the perceived relationships in the data.},
archivePrefix = {arXiv},
arxivId = {1410.7670},
author = {Donalek, Ciro and Djorgovski, S G and Cioc, Alex and Wang, Anwell and Zhang, Jerry and Lawler, Elizabeth and Yeh, Stacy and Mahabal, Ashish and Graham, Matthew and Drake, Andrew and Davidoff, Scott and Norris, Jeffrey S and Longo, Giuseppe},
doi = {10.1109/BigData.2014.7004282},
eprint = {1410.7670},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Donalek et al/IEEE International Conference on Big Data/Donalek et al. - 2014 - Immersive and Collaborative Data Visualization Using Virtual Reality Platforms.pdf:pdf},
isbn = {9781479956661},
journal = {IEEE International Conference on Big Data},
keywords = {and understanding of meaningful,astroinformatics,big data,big data science,data analysis,is not about data,it is about discovery,pattern recognition,that,the key point is,virtual reality,visualization},
pages = {609--614},
title = {{Immersive and Collaborative Data Visualization Using Virtual Reality Platforms}},
year = {2014}
}
@misc{Valve2016a,
author = {{Valve Corporation}},
title = {{SteamVR Plugin}},
url = {https://www.assetstore.unity3d.com/en/{\#}!/content/32647},
urldate = {2017-01-09},
year = {2016}
}
@article{VanDam2002,
abstract = {This article provides a snapshot of immersive virtual reality (IVR) use for scientific visualization, in the context of the evolution of computing in general and of user interfaces in particular. The main thesis of this article is that IVR has great potential for dealing with the serious problem of exponentially growing scientific datasets. Our ability to produce large datasets both through numerical simulation and through data acquisition via sensors is outrunning our ability to make sense of those datasets. While our idea of “large” datasets used to be measured in hundreds of gigabytes, based at least in part on what we could easily store, manipulate, and display in real time, today's science and engineering are producing terabytes and soon even petabytes, both from observation via sensors and as output from numerical simulation. Clearly, visualization by itself will not solve the problem of understanding truly large datasets that would overwhelm both display capacity and the human visual system. We advocate a human–computer partnership that draws on the strengths of each partner, with algorithmic culling and feature-detection used to identify the small fraction of the data that should be visually examined in detail by the human. Our hope is that IVR will be a potent tool to let humans “see” patterns, trends, and anomalies in their data well beyond what they can do with conventional 3D desktop displays.},
author = {van Dam, Andries and Laidlaw, David H and Simpson, Rosemary Michelle},
doi = {10.1016/S0097-8493(02)00113-9},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/van Dam, Laidlaw, Simpson/Computers {\&} Graphics/van Dam, Laidlaw, Simpson - 2002 - Experiments in Immersive Virtual Reality for Scientific Visualization.pdf:pdf},
isbn = {0097-8493},
issn = {00978493},
journal = {Computers {\&} Graphics},
number = {4},
pages = {535--555},
title = {{Experiments in Immersive Virtual Reality for Scientific Visualization}},
volume = {26},
year = {2002}
}
@inproceedings{Walczak2002,
abstract = {A new method of dynamic generation of virtual scenes for use in$\backslash$nInternet virtual reality applications is presented. The virtual scenes$\backslash$nare dynamically generated from virtual scene models coded in a$\backslash$nhigh-level XML-based language called X-VRML. The language consists of a$\backslash$nset of XML tags introducing new elements to programming of virtual$\backslash$nreality. These new elements include object-orientation, access to$\backslash$ndatabases, and programming techniques known from procedural languages$\backslash$nlike variables, conditions, and loops. The X-VRML language overcomes the$\backslash$nmain limitations of current virtual reality systems. Use of X-VRML$\backslash$nsimplifies the code of virtual scene models, allows retrieval of data$\backslash$nfrom databases, selection of virtual scene contents, customization of$\backslash$nvirtual scenes, and efficient coding of elements that have repetitive$\backslash$nstructure. Applications of X-VRML include on-line data visualization,$\backslash$ngeographical information systems, scientific visualization, virtual$\backslash$ngames, and e-commerce applications such as virtual shops},
author = {Walczak, Krzysztof and Cellary, Wojciech},
booktitle = {Proceedings of the 2002 Symposium on Applications and the Internet, SAINT 2002},
doi = {10.1109/SAINT.2002.994479},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Walczak, Cellary/Proceedings - 2002 Symposium on Applications and the Internet, SAINT 2002/X-VRML-XML based modeling of virtual reality.pdf:pdf},
isbn = {0769514472},
keywords = {Content based retrieval,Data visualization,Information retrieval,Internet,Layout,Object oriented databases,Object oriented programming,Virtual reality,Visual databases,XML},
pages = {204--211},
publisher = {IEEE},
title = {{X-VRML-XML Based Modeling of Virtual Reality}},
year = {2002}
}
@article{Stone1999,
author = {Stone, Maureen},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Stone/Unknown/Virtual Reality Modeling Language.pdf:pdf},
journal = {IEE Computer Graphics and Applications},
pages = {1},
title = {{Virtual Reality Modeling Language}},
year = {1999}
}
@misc{Neil2006,
author = {Neil, Ernst},
booktitle = {Semantic Werks},
title = {{When the visual information-seeking mantra fails}},
url = {http://www.neilernst.net/when-the-visual-information-seeking-mantra-fails/},
urldate = {2016-05-20},
year = {2006}
}
@inproceedings{Kwon2015,
abstract = {While virtual reality has been researched in many ways for spatial and scientific visualizations, comparatively little has been explored for visualizations of more abstract kinds of data. In particular, stereoscopic and VR environments for graph visualization have only been applied as limited extensions to standard 2D techniques (e.g. using stereoscopy for highlighting). In this work, we explore a new, immersive approach for graph visualization, designed specifically for virtual reality environments.},
author = {Kwon, Oh Hyun and Muelder, Chris and Lee, Kyungwon and Ma, Kwan Liu},
booktitle = {IEEE Pacific Visualization Symposium},
doi = {10.1109/PACIFICVIS.2015.7156357},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Kwon et al/IEEE Pacific Visualization Symposium/Spherical layout and rendering methods for immersive graph visualization.pdf:pdf},
isbn = {9781467368797},
issn = {21658773},
pages = {63--67},
title = {{Spherical Layout and Rendering Methods for Immersive Graph Visualization}},
volume = {2015-July},
year = {2015}
}
@misc{Blender2016,
author = {{Blender Foundation}},
title = {{Blender}},
url = {https://www.blender.org/download/},
urldate = {2017-01-11},
year = {2016}
}
@article{Laha2012,
abstract = {Volume visualization has been widely used for decades for analyzing datasets ranging from 3D medical images to seismic data to paleontological data. Many have proposed using immersive virtual reality (VR) systems to view volume visualizations, and there is anecdotal evidence of the benefits of VR for this purpose. However, there has been very little empirical research exploring the effects of higher levels of immersion for volume visualization, and it is not known how various components of immersion influence the effectiveness of visualization in VR. We conducted a controlled experiment in which we studied the independent and combined effects of three components of immersion (head tracking, field of regard, and stereoscopic rendering) on the effectiveness of visualization tasks with two x-ray microscopic computed tomography datasets. We report significant benefits of analyzing volume data in an environment involving those components of immersion. We find that the benefits do not necessarily require all three components simultaneously, and that the components have variable influence on different task categories. The results of our study improve our understanding of the effects of immersion on perceived and actual task performance, and provide guidance on the choice of display systems to designers seeking to maximize the effectiveness of volume visualization applications.},
author = {Laha, Bireswar and Sensharma, Kriti and Schiffbauer, James D. and Bowman, Doug A.},
doi = {10.1109/TVCG.2012.42},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Laha et al/IEEE Transactions on Visualization and Computer Graphics/Laha et al. - 2012 - Effects of Immersion on Visual Analysis of Volume Data(2).pdf:pdf},
isbn = {1077-2626 VO - 18},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {3D visualization,CAVE,Immersion,data analysis,micro-CT,virtual environments,virtual reality,volume visualization},
number = {4},
pages = {597--606},
pmid = {22402687},
title = {{Effects of Immersion on Visual Analysis of Volume Data}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6165141},
volume = {18},
year = {2012}
}
@article{Liao1999,
abstract = {Virtual banking is broadly defined in this paper as the provision of banking services via means other than traditional physical branches. Currently, virtual banking exists in the forms of ATM, phone banking, home banking and Internet banking. Understanding people's adoption intention of virtual banking can help financial institutions to formulate appropriate marketing strategies for new forms of banking. Theory of planned behavior (TPB) and innovation diffusion were used to study the adoption intention of virtual banking in a well-developed international financial city. The study finds that the relationships were found only partially explained by the TPB. Other results are interesting and useful for the strategic planning of IT in banking.},
author = {Liao, Shaoyi and Shao, Yuan Pu and Wang, Huaiqing and Chen, Ada},
doi = {10.1016/S0268-4012(98)00047-4},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Liao et al/International Journal of Information Management/Liao et al. - 1999 - The adoption of virtual banking an empirical study.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {banking,information technology,innovation diffusion,virtual banking},
number = {1},
pages = {63--74},
title = {{The adoption of virtual banking: an empirical study}},
volume = {19},
year = {1999}
}
@article{Jamieson2007,
abstract = {As Terabyte datasets become the norm, the focus has shifted away from our ability to produce and store ever larger amounts of data, onto its utilization. It is becoming increasingly difficult to gain meaningful insights into the data produced. Also many forms of the data we are currently producing cannot easily fit into traditional visualization methods. This paper presents a new and novel visualization technique based on the concept of a Data Forest. Our Data Forest has been designed to be used with virtual reality (VR) as its presentation method. VR is a natural medium for investigating large datasets. Our approach can easily be adapted to be used in a variety of different ways, from a stand alone single user environment to large multi-user collaborative environments. A test application is presented using multi-dimensional data to demonstrate the concepts involved.},
author = {Jamieson, Ronan and Alexandrov, Vassil},
doi = {10.1109/IV.2007.9},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Jamieson, Alexandrov/Proceedings of the International Conference on Information Visualisation/Jamieson, Alexandrov - 2007 - A data forest Multi-dimensional visualization.pdf:pdf},
isbn = {0-7695-2900-3},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
keywords = {Data forest,Immersive visualization,Multi-dimensional data,VieGen,Virtual reality},
pages = {293--298},
title = {{A Data Forest: Multi-Dimensional Visualization}},
year = {2007}
}
@book{Shneiderman2005,
abstract = {The much-anticipated fifth edition of Designing the User Interface provides a comprehensive, authoritative introduction to the dynamic field of human-computer interaction (HCI). Students and professionals learn practical principles and guidelines needed to develop high quality interface designs--ones that users can understand, predict, and control. It covers theoretical foundations, and design processes such as expert reviews and usability testing. Numerous examples of direct manipulation, menu selection, and form fill-in give readers an understanding of excellence in design The new edition provides updates on current HCI topics with balanced emphasis on mobile devices, Web, and desktop platforms. It addresses the profound changes brought by user-generated content of text, photo, music, and video and the raised expectations for compelling user experiences.},
author = {Shneiderman, Ben and Plaisant, Catherine},
booktitle = {British dental journal},
doi = {10.1038/sj.bdj.2013.932},
edition = {4},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Shneiderman, Plaisant/British dental journal/Shneiderman, Plaisant - 2005 - Designing the User Interface Strategies for Effective Human-Computer Interaction.pdf:pdf},
isbn = {0321197860},
issn = {1476-5373},
pages = {672},
pmid = {24113932},
publisher = {Addison Wesley},
title = {{Designing the User Interface: Strategies for Effective Human-Computer Interaction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24502408},
year = {2005}
}
@article{Bowman2002,
abstract = {Applications of virtual environments (VEs) are becoming increasingly interactive, allowing the user to not only look around a three-dimensional world, but also to navigate the space, manipulate virtual objects, and give commands to the system. Thus, it is crucial that researchers and developers understand the issues related to 3D interfaces and interaction techniques. In this chapter, we explore the space of possible interaction techniques for several common tasks, and offer guidelines for their use in VE applications. These guidelines are drawn largely from empirical research results.},
author = {Bowman, Doug A.},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Bowman/Handbook of Virtual Environments/Bowman - 2002 - Principles for the Design of Performance-oriented Interaction Techniques.pdf:pdf},
journal = {Handbook of Virtual Environments},
pages = {277--300},
title = {{Principles for the Design of Performance-oriented Interaction Techniques}},
url = {http://people.cs.vt.edu/{~}bowman/papers/hvet.pdf},
year = {2002}
}
@article{Soldati2007,
abstract = {We present SphereViz, a novel 3D user interface for the visual exploration of multi-dimensional data sets in virtual reality environments. SphereViz builds on known visualization and search concepts like RadViz and RelevanceSphere. It combines them with 3D-interaction techniques like World in Miniature for projection in virtual environments. A prototype implementation of SphereViz allows to study, on one hand, the visualization methods of images in 3D space, and on the other hand, intuitive search methods and adequate interaction techniques.},
author = {Soldati, Marco and Doulis, Mario and Csillaghy, Andr{\'{e}}},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Soldati, Doulis, Csillaghy/11th International Conference Information Visualization (IV'07)/Soldati, Doulis, Csillaghy - 2007 - SphereViz - Data Exploration in a Virtual Reality Environment.pdf:pdf},
isbn = {0769529003},
journal = {11th International Conference Information Visualization (IV'07)},
title = {{SphereViz - Data Exploration in a Virtual Reality Environment}},
year = {2007}
}
@misc{Gizmodo2015,
author = {Gizmodo},
title = {{This Is How Valve's Amazing Lighthouse Tracking Technology Works}},
url = {http://gizmodo.com/this-is-how-valve-s-amazing-lighthouse-tracking-technol-1705356768},
urldate = {2016-03-27},
year = {2015}
}
@article{Drouhard2015,
abstract = {In this paper, we propose strategies and objectives for immersive data visualization with applications in materials science using the Oculus Rift virtual reality headset. We provide background on currently available analysis tools for neutron scattering data and other large-scale materials science projects. In the context of the current challenges facing scientists, we discuss immersive virtual reality visualization as a potentially powerful solution. We introduce a prototype immersive visual- ization system, developed in conjunction with materials scientists at the Spallation Neutron Source, which we have used to explore large crystal structures and neutron scattering data. Finally, we offer our perspective on the greatest challenges that must be addressed to build effective and intuitive virtual reality analysis tools that will be useful for scientists in a wide range of fields},
author = {Drouhard, Margaret and Steed, Chad A and Hahn, Steven and Proffen, Thomas and Daniel, Jamison and Matheson, Michael},
doi = {10.1109/BigData.2015.7364040},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Drouhard et al/Unknown/Drouhard et al. - 2015 - Immersive Visualization for Materials Science Data Analysis using the Oculus Rift.pdf:pdf},
isbn = {978-1-4799-9926-2},
pages = {2453--2461},
title = {{Immersive Visualization for Materials Science Data Analysis using the Oculus Rift}},
year = {2015}
}
@article{Wann1996,
abstract = {Virtual reality (VR) has invaded the public's awareness through a series of media articles that have promoted it as a new and exciting form of computer interaction. We discuss the extent to which VR may be a useful tool in visualization and attempt to disambiguate the use of VR as a general descriptor for any three-dimensional computer presentation. The argument is presented that, to warrant the use of the term virtual environment (VE), the display should satisfy criteria that arise from the nature of human spatial perception. It directly follows, therefore, that perceptual criteria are the foundations of an effective VE display. We address the task of making a VE system easy to navigate, traverse and engage, by examining the ways in which three-dimensional perception and perception of motion may be supported, and consider the potential conflict that may arise between depth cues. We propose that the design of VE systems must centre on the perceptual-motor capabilities of the user, in the context of the task to be undertaken, and establish what isessential, desirableandoptimalin order to maximize the task gains, while minimizing the learning required to operate within three-dimensional interactive displays.},
author = {Wann, John and Mon-Williams, Mark},
doi = {10.1006/ijhc.1996.0035},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Wann, Mon-Williams/International Journal of Human-Computer Studies/Wann, Mon-Williams - 1996 - What does virtual reality NEED human factors issues in the design of three-dimensional computer environments.pdf:pdf},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {829--847},
title = {{What does virtual reality NEED?: human factors issues in the design of three-dimensional computer environments}},
url = {http://www.sciencedirect.com/science/article/pii/S107158199690035X},
volume = {44},
year = {1996}
}
@misc{Oculus2016,
author = {Oculus},
title = {{Oculus Rift is Shipping}},
url = {https://www3.oculus.com/en-us/blog/oculus-rift-is-shipping/},
urldate = {2016-06-01},
year = {2016}
}
@inproceedings{Shneiderman1996,
abstract = {A useful starting point for designing advanced graphical user$\backslash$ninterfaces is the visual information seeking Mantra: overview first,$\backslash$nzoom and filter, then details on demand. But this is only a starting$\backslash$npoint in trying to understand the rich and varied set of information$\backslash$nvisualizations that have been proposed in recent years. The paper offers$\backslash$na task by data type taxonomy with seven data types (one, two, three$\backslash$ndimensional data, temporal and multi dimensional data, and tree and$\backslash$nnetwork data) and seven tasks (overview, zoom, filter,$\backslash$ndetails-on-demand, relate, history, and extracts)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Shneiderman, Ben},
booktitle = {Proceedings 1996 IEEE Symposium on Visual Languages},
doi = {10.1109/VL.1996.545307},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Shneiderman/Proceedings 1996 IEEE Symposium on Visual Languages/Shneiderman - 1996 - The Eyes Have It A Task by Data Type Taxonomy for Information Visualizations.pdf:pdf},
isbn = {0-8186-7508-X},
issn = {1049-2615},
pages = {336--343},
pmid = {4986861},
publisher = {IEEE},
title = {{The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations}},
year = {1996}
}
@inproceedings{Deligiannidis2003,
abstract = {The Industrial and Manufacturing Engineering Department at Wichita State University is developing an integrated set of virtual reality models of a manufacturing line of Boeing Wichita. The purpose of this research is to help Boeing and other aerospace manufacturers improve their manufacturing operations. In our virtual environment, a fully immersed person is working on a specific task and several (up to 20) outsiders (participants) observe the fully, immersed person and would like to comment and affect the fully immersed person's work. The lack of interaction between the fully immersed person and the participants is the most critical issue. The current communication technique used is vocal instruction, which is distracting to everyone. This paper presents a technique in which the fully immersed person and the participants can interact using a second camera directed for a third person's view of the environment. This technique attempts to provide the best of both worlds (first and third person views) so the formerly passive participants can become more immersed in the environment.},
author = {Deligiannidis, L. and Whitman, L.},
booktitle = {IEEE Virtual Reality, 2003. Proceedings.},
doi = {10.1109/VR.2003.1191159},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Deligiannidis, Whitman/IEEE Virtual Reality, 2003. Proceedings/Deligiannidis, Whitman - 2003 - User interaction in a power-wall based virtual reality environment.pdf:pdf},
isbn = {0-7695-1882-6},
issn = {1087-8270},
keywords = {Aerospace engineering,Aerospace industry,Boeing,Cameras,Control systems,Manufacturing industries,Navigation,Power engineering and energy,Virtual environment,Virtual manufacturing,Virtual reality,aerospace industry,aerospace manufacturers,camera,computer integrated manufacturing,human factors,manufacturing line,power-wall based virtual reality environment,user interaction,user interfaces,virtual reality,vocal instruction},
pages = {279--280},
publisher = {IEEE Comput. Soc},
shorttitle = {Virtual Reality, 2003. Proceedings. IEEE},
title = {{User Interaction in a Power-Wall Based Virtual Reality Environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1191159},
year = {2003}
}
@misc{CodeScience2015,
author = {CodeScience},
title = {{Using Oculus Rift and Virtual Reality to Visualize Data on Salesforce}},
url = {https://www.youtube.com/watch?v=oboOkHmwr{\_}Q},
urldate = {2016-11-30},
year = {2015}
}
@inproceedings{Takala2014,
abstract = {Summary form only given. Recently a number of affordable game controllers have been adopted by virtual reality (VR) researchers [1][4]. We present a video1 of a VR demo called TurboTuscany, where we employ such controllers; our demo combines a Kinect controlled full body avatar with Oculus Rift head-mounted-display [2]. We implemented three positional head tracking schemes that use Kinect, Razer Hydra, and PlayStation (PS) Move controllers. In the demo the Kinect tracked avatar can be used to climb ladders, play with soccer balls, and otherwise move or interact with physically simulated objects. PS Move or Razer Hydra controller is used to control locomotion, and for selecting and manipulating objects. Our subjective experience is that the best head tracking immersion is achieved by using Kinect together with PS Move, as the latter is more accurate and responsive while having a large tracking volume. We also noticed that Oculus Rift's orientation tracking has less latency than any of the positional trackers that we used, while Razer Hydra has less latency than PS Move, and Kinect has the largest latency. Besides positional tracking, our demo uses these three trackers to correct the yaw drift of Oculus Rift. TurboTuscany was developed by using our RUIS toolkit, which is a software platform for VR application development [3]. The demo and RUIS toolkit can be downloaded online2.},
author = {Takala, Tuukka M. and Matveinen, Mikael},
booktitle = {2014 IEEE Virtual Reality (VR)},
doi = {10.1109/VR.2014.6802099},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Takala, Matveinen/2014 IEEE Virtual Reality (VR)/Takala, Matveinen - 2014 - Full body interaction in virtual reality with affordable hardware.pdf:pdf},
isbn = {978-1-4799-2871-2},
keywords = {Avatars,Games,Hardware,Kinect controlled full body avatar,Media,Oculus Rift head-mounted-display,PS Move controller,PlayStation Move controller,RUIS toolkit,Razer Hydra controller,Tracking,TurboTuscany,VR application development,VR demo,avatars,computer games,game controllers,helmet mounted displays,ladders,locomotion control,motion control,object manipulation,object selection,object tracking,physically simulated objects,positional head tracking schemes,soccer balls,software platform,virtual reality},
month = {mar},
pages = {157--157},
publisher = {IEEE},
shorttitle = {Virtual Reality (VR), 2014 iEEE},
title = {{Full Body Interaction in Virtual Reality with Affordable Hardware}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6802099},
year = {2014}
}
@article{Bowman2002a,
abstract = {Virtual environments (VEs) are a relatively new type of human–computer interface in which users perceive and act in a three-dimensional world. The designers of such systems cannot rely solely on design guidelines for traditional two-dimensional interfaces, so usability evaluation is crucial for VEs. This paper presents an overview of VE usability evaluation to organize and critically analyze diverse work from this field. First, we discuss some of the issues that differentiate VE usability evaluation from evaluation of traditional user interfaces such as GUIs. We also present a review of some VE evaluation methods currently in use, and discuss a simple classification space for VE usability evaluation methods. This classification space provides a structured means for comparing evaluation methods according to three key characteristics: involvement of representative users, context of evaluation, and types of results produced. Finally, to illustrate these concepts, we compare two existing evaluation approaches...},
author = {Bowman, Doug a. and Gabbard, Joseph L. and Hix, Deborah},
doi = {10.1162/105474602760204309},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Bowman, Gabbard, Hix/Presence Teleoperators and Virtual Environments/Bowman, Gabbard, Hix - 2002 - A Survey of Usability Evaluation in Virtual Environments Classification and Comparison of Methods.pdf:pdf},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {4},
pages = {404--424},
title = {{A Survey of Usability Evaluation in Virtual Environments: Classification and Comparison of Methods}},
volume = {11},
year = {2002}
}
@inproceedings{Muller1998,
abstract = {A system for the visualization of three-dimensional anatomical data, derived from magnetic resonance imaging (MRI) or computed tomography (CT), enables the physician to navigate through and interact with the patient's 3D scans in a virtual environment. This paper presents the multimodal human-machine interaction focusing the speech input. For the concerned task, a speech understanding front-end using a special kind of semantic decoder was successfully adopted. Now, the navigation as well as certain parameters and functions can be directly accessed by spoken commands. Using the implemented interaction modalities, the speed and efficiency of the diagnosis could be considerably improved},
author = {Muller, J. and Krapichler, C. and {Hans Englmeier}, K. and Lang, M.},
booktitle = {Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
doi = {10.1109/ICASSP.1998.679701},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Muller et al/Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)/Muller et al. - 1998 - Speech interaction in virtual reality.pdf:pdf},
isbn = {0-7803-4428-6},
issn = {1520-6149},
keywords = {CT,Computed tomography,Data visualization,Decoding,Focusing,MRI,Magnetic resonance imaging,Man machine systems,Navigation,Speech,Virtual environment,Virtual reality,anatomical data visualization,biomedical NMR,computed tomography,computerised tomography,data visualisation,decoding,efficiency,magnetic resonance imaging,multimodal human-machine interaction,natural language interfaces,navigation,patient 3D scans,patient diagnosis,semantic decoder,speech input,speech interaction,speech processing,speech understanding front-end,speed,spoken commands,virtual environment,virtual reality},
pages = {3757--3760},
publisher = {IEEE},
shorttitle = {Acoustics, Speech and Signal Processing, 1998. Pro},
title = {{Speech interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=679701},
volume = {6},
year = {1998}
}
@misc{vrs2015,
author = {{Virtual Reality Society}},
title = {{History of Virtual Reality}},
url = {http://www.vrs.org.uk/virtual-reality/history.html},
urldate = {2016-05-21},
year = {2015}
}
@article{Carey1998,
abstract = {VRML stands for Virtual Reality Modeling Language. Technically,$\backslash$nVRML is neither virtual reality nor a modeling language. Virtual reality$\backslash$ngenerally implies an immersive 3D experience, which typically requires a$\backslash$nhead mounted display (HMD) and 3D input devices, such as digital gloves.$\backslash$nVRML neither requires nor imposes immersion. Furthermore, a true$\backslash$nmodeling language would contain richer geometric modeling primitives and$\backslash$nmechanisms. VRML provides a bare minimum of geometric modeling features$\backslash$nbut contains numerous features unavailable in a modeling language. If$\backslash$nVRML is not virtual reality or a modeling language, what is it? This$\backslash$nquestion has several answers. At its core, VRML serves as a 3D$\backslash$ninterchange format. It defines most of the commonly used semantics found$\backslash$nin today's 3D applications such as hierarchical transformations, light$\backslash$nsources, viewpoints, geometry, animation, fog, material properties, and$\backslash$ntexture mapping. Here's a second answer to: what is VRML? It's a 3D$\backslash$nanalog to HTML. This means that VRML serves as a simple, multiplatform$\backslash$nlanguage for publishing 3D Web pages. The fact that some information,$\backslash$nincluding games, engineering models, scientific visualizations,$\backslash$neducational experiences, and architecture, can best be experienced in 3D$\backslash$nhas motivated this language. Typically, these types of projects require$\backslash$nintensive interaction, animation, and user participation and exploration$\backslash$nbeyond what a page, text, or image based format can handle. Another$\backslash$nanswer is that VRML provides the technology to integrate 3D, 2D, text,$\backslash$nand multimedia into a coherent model},
author = {Carey, R.},
doi = {10.1109/93.713310},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Carey/IEEE Multimedia/The virtual reality modeling language explained.pdf:pdf},
isbn = {1070-986X},
issn = {1070-986X},
journal = {IEEE Multimedia},
pages = {84--93},
title = {{The virtual reality modeling language explained}},
volume = {5},
year = {1998}
}
@inproceedings{Bolt1980,
abstract = {Recent technological advances in connected-speech recognition and position sensing in space have encouraged the notion that voice and gesture inputs at the graphics interface can converge to provide a concerted, natural user modality. The work described herein involves the user commanding simple shapes about a large-screen graphics display surface. Because voice can be augmented with simultaneous pointing, the free usage of pronouns becomes possible, with a corresponding gain in naturalness and economy of expression. Conversely, gesture aided by voice gains precision in its power to reference.},
author = {Bolt, Richard a},
booktitle = {Proceedings of the 7th annual conference on Computer graphics and interactive techniques - SIGGRAPH '80},
doi = {10.1145/800250.807503},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Bolt/Proceedings of the 7th annual conference on Computer graphics and interactive techniques - SIGGRAPH '80/Bolt - 1980 - “Put-that-there” Voice and Gesture at the Graphics Interface.pdf:pdf},
isbn = {0897910214},
issn = {00978930},
keywords = {Voice input,gesture,graphics,graphics interface.,man-machine interfaces,space sensing,spatial data management,speech input},
pages = {262--270},
title = {{“Put-that-there”: Voice and Gesture at the Graphics Interface}},
year = {1980}
}
@inproceedings{Celentano2002,
abstract = {We merge the Pictorial Computing Laboratory (PCL) approach to WIMP interaction with the Interaction Locus approach to structuring visual spaces as a step toward the definition of a rational methodology for the design of Virtual Reality interactive systems. The merging of the two points of view allows the refinement of the model of interaction of a user with a virtual environment and leads to the definition of "real" and "virtual" characteristic pattern.},
author = {Celentano, A. and Fogli, D. and Mussio, P. and Pittarello, F.},
booktitle = {Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments},
doi = {10.1109/HCC.2002.1046343},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Celentano et al/Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments/Celentano et al. - 2002 - Virtual reality interaction the characteristic pattern approach.pdf:pdf},
isbn = {0-7695-1644-0},
keywords = {Character generation,Design methodology,Educational programs,Human computer interaction,Interaction Locus approach,Interactive systems,Laboratories,Layout,Merging,Pictorial Computing Laboratory,Virtual environment,Virtual reality,WIMP interaction,real characteristic pattern,user interfaces,virtual characteristic pattern,virtual reality,virtual reality interactive system design,visual space structuring},
pages = {48--50},
publisher = {IEEE Comput. Soc},
shorttitle = {Human Centric Computing Languages and Environments},
title = {{Virtual Reality Interaction: the Characteristic Pattern Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1046343},
year = {2002}
}
@inproceedings{Khundam2015,
abstract = {Virtual reality (VR) has become a very popular technology in recent years, which used in the field of multimedia for various purposes. One of the applications that widely used for simulating physical presence in the real world is walk-through VR. In the walk-through VR system will generate simulation character or avatar for user which able to control movement, especially first person movement walk-through in VR with many input devices. In this paper, we present a human - computer interaction with the connection of Oculus Rift and Leap Motion new technological devices for VR. Oculus Rift is VR headset or head - mounted display devices that have a small display optic in front of each eye. Oculus Rift can track head movement and change view point follow it. Leap Motion is in - air controller that can track hand gesture of the user. The combination of them will make users feel like immerse to VR. Users can move avatar any way in VR by their hand interact through the system via these devices. We introduce a new interactive hand gesture system with palm normal for control steering develop by the game engine Unity3D applies synchronization of Oculus Rift and Leap Motion. Our design and development method will allow users to adjust moving speed follows the hand gesture and the range of the user's hand that make a smoothly moving with acceleration.},
author = {Khundam, Chaowanan},
booktitle = {2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
doi = {10.1109/JCSSE.2015.7219818},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Khundam/2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)/07219818.pdf:pdf},
isbn = {978-1-4799-1966-6},
keywords = {Avatars,Computers,Engines,Game Engine,Games,Head - Mounted Display,Headphones,Human - Computer Interaction,In - Air Controller,Leap Motion new technological devices,Oculus Rift,Three-dimensional displays,Tracking,Unity3D game engine,Virtual Reality,avatar,avatars,digital simulation,first person movement control,gesture recognition,hand gesture interaction,human computer interaction,human-computer interaction,motion control,multimedia,palm normal,physical presence simulation,simulation character,small display optic,virtual reality,walk-through VR},
month = {jul},
pages = {325--330},
publisher = {IEEE},
shorttitle = {Computer Science and Software Engineering (JCSSE),},
title = {{First Person Movement Control with Palm Normal and Hand Gesture Interaction in Virtual Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7219818},
year = {2015}
}
@misc{Htcvive2016a,
author = {{HTC Vive}},
title = {{Vive Setup}},
url = {https://www.htcvive.com/us/setup/},
urldate = {2016-05-14},
year = {2016}
}
@inproceedings{Woodard2015,
address = {Fort Lauderdale, Florida},
author = {Woodard, Will and Sukittanon, Somsak},
booktitle = {Proceedings of the IEEE SoutheastCon 2015},
doi = {10.1109/SECON.2015.7132929},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Woodard, Sukittanon/Unknown/Interactive virtual building walkthrough using Oculus Rift and Microsoft Kinect.pdf:pdf},
isbn = {9781467373005},
pages = {5--7},
publisher = {IEEE},
title = {{Interactive Virtual Building Walkthrough Using Oculus Rift and Microsoft Kinect}},
year = {2015}
}
@article{Ribarsky1994,
abstract = {Current virtual reality technologies have not yet crossed the threshold of usability. Not surprisingly, VR has so far shown more promise than practical applications. Yet the promise looks bright for fields such as data visualization and analysis. For such problems, VR offers a natural interface between human and computer that will simplify complicated manipulations of the data. It also provides an opportunity to rely on the interplay of combined senses rather than on a single or even dominant sense. Still, we cannot yet say whether VR is better than other visualization and analysis approaches for certain classes of data and, if so, by how much. The payoff will come not for those applications or tasks for which VR is merely better, even if significantly, but for those applications or tasks for which it offers some unique advantage unavailable otherwise. To answer these questions, we embarked on a multipronged program involving the Graphics, Visualization. and Usability (GVU) Center, the Office of Information Technology Scientific Visualization Lab. and other research groups at Georgia Tech. Integration is mandatory since these questions involve basic considerations: how immersive environments affect user interfaces and human-computer interactions; the ranges and capabilities of sensors; computer graphics and the VR optical system; and applications' needs. We describe some of our results},
author = {Ribarsky, W. and Bolter, J. and Bosch, a. Op Den and Teylingen, R. Van},
doi = {10.1109/38.250911},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ribarsky et al/IEEE Computer Graphics and Applications/Visualization and analysis using virtual reality.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
number = {1},
pages = {10--12},
title = {{Visualization and Analysis Using Virtual Reality}},
volume = {14},
year = {1994}
}
@article{Smith1987,
abstract = {This paper presents an overview of the Alternate Reality Kit (ARK), an animated environment for creating interactive simulations. ARK is built upon a physical-world metaphor: all objects have an image, a position, a velocity, and can experience forces. Users manipulate objects with a mouse-operated "hand" which enables them to carry and throw objects, to press buttons, and to operate sliders. The interface features are discussed in light of a general user interface tension between literalism and magic. Literal features are defined to be those that are true to the interface's metaphor. Literal features enhance an interface's learnability. Magical features are defined to'be those capabilities that deliberately violate the metaphor in order to provide enhanced functionality. Discussion of each ARK feature includes informal observations of early ARK users, an assessment of the feature's learnability, of its usefulness, and of its position on the magical-literal axis. Even though ARK includes magical features, applications-level users have be trained in a few minutes. Although this paper is about ARK, the tension between literalism and magic raises some interesting questions on its own. Some of these questions},
author = {Smith, Randall B.},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Smith/IEEE CG{\&}A/Smith - 1987 - Experiences With The Alternate Reality Kit An Example of the Tension Between Literalism and Magic.pdf:pdf},
isbn = {0897912136},
journal = {IEEE CG{\&}A},
pages = {61--67},
title = {{Experiences With The Alternate Reality Kit: An Example of the Tension Between Literalism and Magic}},
year = {1987}
}
@misc{Sony2010,
author = {{Sony Computer Entertainment}},
title = {{PLAYSTATION{\textregistered} MOVE MOTION CONTROLLER TO HIT WORLDWIDE MARKET STARTING THIS SEPTEMBER}},
url = {http://us.playstation.com/corporate/about/press-release/545.html},
urldate = {2016-04-03},
year = {2010}
}
@misc{TableauSoftware2016,
author = {{Tableau Software}},
title = {{Tableau Desktop}},
url = {https://www.tableau.com/products/desktop},
urldate = {2016-12-08},
year = {2016}
}
@inproceedings{He2009,
abstract = {The growing complexity of virtual reality simulations and the inclusion of a greater range and number of events and interactions in such simulations precipitates the need for the recording of these events to allow their subsequent viewing, discussion and perhaps modification. Furthermore, storage of such recordings in a format defined by an international standard allows their easy use and accessibility as well as distribution. This paper presents a framework for MPEG-4 based recording and replay of virtual reality sessions.},
author = {He, Zhiyong and Zhao, Chunsheng},
booktitle = {2009 International Conference on Communication Software and Networks},
doi = {10.1109/ICCSN.2009.80},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/He, Zhao/2009 International Conference on Communication Software and Networks/He, Zhao - 2009 - A Recording Method of Virtual Reality Interaction.pdf:pdf},
isbn = {978-0-7695-3522-7},
keywords = {Collaboration,Computational modeling,Computer science,Computer simulation,Discrete event simulation,Disk recording,Interaction,Layout,MPEG 4 Standard,MPEG-4,MPEG-4 based recording,Recording,Streaming media,Virtual realit,Virtual reality,audio recording,multimedia communication,recording method,video recording,virtual reality,virtual reality interaction},
pages = {666--669},
publisher = {IEEE},
shorttitle = {Communication Software and Networks, 2009. ICCSN '},
title = {{A Recording Method of Virtual Reality Interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5076938},
year = {2009}
}
@misc{Gartner2015b,
author = {Gartner},
title = {{What's New in Gartner's Hype Cycle for Emerging Technologies, 2015}},
url = {http://www.gartner.com/smarterwithgartner/whats-new-in-gartners-hype-cycle-for-emerging-technologies-2015/},
urldate = {2016-06-20},
year = {2015}
}
@misc{Sysdia2017,
author = {{Sysdia Solutions Ltd}},
title = {{VRTK - SteamVR Unity Toolkit}},
url = {https://www.assetstore.unity3d.com/en/{\#}!/content/64131},
urldate = {2017-01-10},
year = {2017}
}
@article{Burlutskiy2014a,
abstract = {Complexity and scale of modern data is at its highest level but its temporal properties are often neglected. As a result, it is often hard for a user to make an informed decision about its time related characteristics. However, an aesthetic and efficient visualization can mitigate this drawback of data representation. For example, an informative graphical visualization based on user's interaction with a computer interface can dramatically improve user experience with temporal data. In this paper, I propose such visualization of temporal data for reasoning. I developed a temporal model supporting different temporal entities for this data. These include timestamps, intervals, different time granularity and uncertainty of time. I proposed a multimodal visualization based on this abstract time model so a user will have the functionality to reason on temporal properties of visualized data from different points of view.},
author = {Burlutskiy, Nikolay and Petridis, Miltos and Fish, Andrew and Ali, Nour},
doi = {10.1109/VLHCC.2014.6883044},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Burlutskiy et al/Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VLHCC/Burlutskiy et al. - 2014 - Enabling the visualization for reasoning about temporal data.pdf:pdf},
isbn = {9781479940356},
issn = {19436106},
journal = {Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC},
pages = {179--180},
title = {{Enabling the Visualization for Reasoning about Temporal Data}},
year = {2014}
}
@article{Moore1999,
author = {Moore, C W and McClurg, D C and Soreide, N N and Hermann, A J and Lascara, C M and Wheless, G H},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Moore et al/Unknown/Moore et al. - 1999 - Exploring 3-dimensional oceanographic data sets on the Web using virtual reality modeling language.pdf:pdf},
number = {Idl},
pages = {1501--1503},
title = {{Exploring 3-dimensional oceanographic data sets on the Web using virtual reality modeling language}},
volume = {3},
year = {1999}
}
@book{Hevner2010,
address = {Boston, MA},
author = {Hevner, Alan and Chatterjee, Samir},
doi = {10.1007/978-1-4419-5653-8},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Hevner, Chatterjee/Unknown/Hevner, Chatterjee - 2010 - Design Research in Information Systems.pdf:pdf},
isbn = {978-1-4419-5652-1},
keywords = {Design Research},
mendeley-tags = {Design Research},
pages = {320},
publisher = {Springer US},
series = {Integrated Series in Information Systems},
title = {{Design Research in Information Systems}},
volume = {22},
year = {2010}
}
@book{Creswell2014,
address = {Thousand Oaks, CA},
author = {Creswell, John W.},
edition = {4},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Creswell/Unknown/Creswell - 2014 - Research Design Qualitative, Quantitative, and Mixed Methods Approaches.pdf:pdf},
isbn = {978-1-4522-2610-1},
pages = {342},
publisher = {Sage Publications, Inc.},
title = {{Research Design: Qualitative, Quantitative, and Mixed Methods Approaches}},
year = {2014}
}
@misc{Google2016,
author = {Google},
booktitle = {Steam},
title = {{Tilt Brush}},
url = {http://store.steampowered.com/app/327140/},
urldate = {2016-04-11},
year = {2016}
}
@article{Peffers2012,
abstract = {The consensus view is that the rigorous evaluation of design science (DS) artifacts is essential. There are many types of DS artifacts and many forms of evaluation; what is missing is guidance for how to perform the evaluation, more specifically, what evaluation methods to use with specific DS research outputs. Here we find and review 148 DS research articles published in a se- lected set of information systems (IS), computer science (CS) and engineering journals. We analyze the articles to develop taxonomies of DS artifact types and artifact evaluation methods; we apply these taxonomies to determine which evaluation methods are associated in the literature with particular artifacts. We show that there are several popular “artifact - evaluation method” combinations in the literature. The results inform DS researchers of usual and customary combinations of research artifacts and evaluation methods, potentially provid- ing them with rationale and justification for an evaluation method selection.},
author = {Peffers, K. and Rothenberger, M. and Tuunanen, T. and Vaezi, R.},
doi = {10.1007/978-3-642-29863-9_29},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Peffers et al/Design Science Research in Information Systems. Advances in Theory and Practice/Peffers et al. - 2012 - Design Science Research Evaluation.pdf:pdf},
isbn = {978-3-642-29863-9},
issn = {0302-9743},
journal = {Design Science Research in Information Systems. Advances in Theory and Practice},
keywords = {artifacts,design science,evaluation},
pages = {398--410},
title = {{Design Science Research Evaluation}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-29863-9{\_}29},
year = {2012}
}
@misc{CloudheadGames2016,
author = {{Cloudhead Games ltd.}},
booktitle = {Steam},
title = {{The Gallery - Episode 1: Call of the Starseed}},
url = {http://store.steampowered.com/app/270130/},
urldate = {2016-04-11},
year = {2016}
}
@misc{UBSAG2016,
author = {{UBS AG}},
title = {{Trial e-banking demo}},
url = {https://www.ubs.com/ebanking-demo-en},
urldate = {2016-12-22},
year = {2016}
}
@article{Ankerst1996,
abstract = {In this paper, we describe a novel technique for visualizing large amounts of high-dimensional data, called ‘circle segments'. The technique uses one colored pixel per data value and can therefore be classified as a pixel-per-value technique [Kei 96]. The basic idea of the ‘circle segments' visualization technique is to display the data dimensions as segments of a circle. If the data consists of k dimensions, the circle is partitioned into k segments, each repre- senting one data dimension. Inside the segments, the data values belonging to one dimension are arranged from the center of the cir- cle to the outside in a back and forth manner orthogonal to the line that halves the segment. Our first results show that the ‘circle seg- ment' technique is very powerful for visualizing large amounts of data, providing more expressive visualizations than other well- known techniques such as the ‘recursive pattern' technique and tra- ditional ‘line graphs'.},
author = {Ankerst, Mihael and Keim, Da and Kriegel, Hp},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ankerst, Keim, Kriegel/Proc. IEEE Visualization '96, Hot Topic Session/Ankerst, Keim, Kriegel - 1996 - 'Circle Segments' A Technique for Visually Exploring Large Multidimensional Data Sets.pdf:pdf},
journal = {Proc. IEEE Visualization '96, Hot Topic Session},
pages = {5--8},
title = {{'Circle Segments': A Technique for Visually Exploring Large Multidimensional Data Sets}},
url = {https://kops.ub.uni-konstanz.de/xmlui/bitstream/handle/urn:nbn:de:bsz:352-opus-70761/Circle{\_}Segments.pdf?sequence=1},
year = {1996}
}
@misc{Htcvive2016,
author = {{HTC Vive}},
title = {{Unveiling the Vive Consumer Edition and Pre-order Information}},
url = {http://blog.htcvive.com/us/2016/02/unveiling-the-vive-consumer-edition-and-pre-order-information/},
urldate = {2016-04-02},
year = {2016}
}
@article{Hevner2004,
archivePrefix = {arXiv},
arxivId = {http://dl.acm.org/citation.cfm?id=2017212.2017217},
author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
doi = {10.2307/25148625},
eprint = {/dl.acm.org/citation.cfm?id=2017212.2017217},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Hevner et al/MIS Quarterly/Hevner et al. - 2004 - Design Science in Information Systems Research.pdf:pdf},
isbn = {1702807118},
issn = {02767783},
journal = {MIS Quarterly},
keywords = {Information Systems research methodologies,busi-,business environment,creativity,design artifact,design science,experimental methods,information systems research meth-,odologies,search strategies,technology infrastructure},
number = {1},
pages = {75--105},
pmid = {12581935},
primaryClass = {http:},
title = {{Design Science in Information Systems Research}},
volume = {28},
year = {2004}
}
@inproceedings{Hentschel2009,
abstract = {The analysis of time-dependent simulation data is a demanding task, both in terms of computing power and time. Interactive analysis using multiple linked views has been shown to be one possible solution to this problem. However, there are two significant short-comings when limited to a standard desktop-based setup: first, complex spatial relationships are hard to understand using only 2D projections of the data. Second, the size of today's simulation runs is too large to be handled even by powerful workstations. We describe a system for the interactive analysis of large, time-dependent data in virtual environments. Based on the techniques of multiple linked views and brushing, our approach allows the user to quickly formulate, visualize and assess hypotheses about the data. To enable an interactive exploration even in the face of multi-gigabyte data sets, we distribute the workload to a multi-processor parallel machine and a rendering client.},
author = {Hentschel, Bernd and Wolter, Marc and Kuhlen, Torsten},
booktitle = {Proceedings - IEEE Virtual Reality},
doi = {10.1109/VR.2009.4811041},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Hentschel, Wolter, Kuhlen/Proceedings - IEEE Virtual Reality/Virtual Reality-Based Multi-View Visualization of Time-Dependent Simulation Data.pdf:pdf},
isbn = {9781424439430},
issn = {1087-8270},
keywords = {I.3.6 [computer graphics]: Interaction techniques,Virtual reality I.6.6 [Simulation and Modelling]:S,[I.3.7]: Computer graphics},
pages = {253--254},
title = {{Virtual Reality-Based Multi-View Visualization of Time-Dependent Simulation Data}},
year = {2009}
}
@inproceedings{Uchino2008,
abstract = {In this research, a dialog environment between human and virtual agent has been constructed. With the commercial off-the-shelf VR technologies, special devices such as data glove have to be used for the interaction. But this is difficult to manipulate objects. If there is a helper who has direct access to objects in a virtual space, we may ask him. The question, however, is how to communicate with the helper. This paper presents a solution to the question. The basic idea is to utilize speech recognition and gesture recognition systems. Experimental results have proved the effectiveness of the approach in terms of facilitating man-machine interaction and communication. The environment constructed in this research allows a user to communicate by talking and showing gestures to a personified agent in virtual environment. A user can use his/her finger to point at a virtual object and ask the agent to manipulate the virtual object.},
author = {Uchino, Shunji and Abe, Norihiro and Takada, Hiroshi and Yagi, Tetsuya and Taki, Hirokazu and He, Shoujie},
booktitle = {22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)},
doi = {10.1109/WAINA.2008.124},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Uchino et al/22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)/Uchino et al. - 2008 - Virtual Reality Interaction System between User and Ava.pdf:pdf},
isbn = {978-0-7695-3096-3},
keywords = {Avatar,Avatars,Data gloves,Dialog Environment,Distributed processing,Fingers,Humans,Internet Meeting System,Man machine systems,Space technology,Speech recognition,Virtual Agent,Virtual environment,Virtual reality,avatar,avatars,dialog environment,distributed processing,gesture recognition systems,man-machine communication,man-machine interaction,personified agent,speech recognition,speech-based user interfaces,virtual agent,virtual object manipulation,virtual reality interaction system},
pages = {1034--1039},
publisher = {IEEE},
shorttitle = {Advanced Information Networking and Applications -},
title = {{Virtual Reality Interaction System between User and Avatar with Distributed Processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4483053},
year = {2008}
}
@inproceedings{Ariyana2012,
abstract = {Information technology currently supports the development of human interaction with virtual environment, this development will continue in developing in the form of Human Computer Interaction (HCI). In this study, how the environment 3D virtual computer should be able to recognize human hand as part as virtual object, so it can interact with virtual environment. HCI is a study in which the relationship between humans and computing technology and how computers are designed for easy to use by human, more practical and more intuitive. HCI emphasizes how human interaction with computer technology. This research is using interaction technique in virtual environment to interact between human hand and virtual object. Tracker is needed in virtual interaction by using Augmented Reality (AR), the problem that arise in AR is how to read marker, so it can display a virtual object that has been computed before, basically is how to read the geometry model of human hand, then the result from the processing of the human hand model geometry is used as a marker, so it can interact with a virtual environment on AR as one of the HCI model implementation. This process is intended for the movement of human hands that have been read as a virtual object can communicate virtually using image processing.},
author = {Ariyana, Y. and Wuryandari, A. I.},
booktitle = {2012 International Conference on Cloud Computing and Social Networking (ICCCSN)},
doi = {10.1109/ICCCSN.2012.6215734},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Ariyana, Wuryandari/2012 International Conference on Cloud Computing and Social Networking (ICCCSN)/Ariyana, Wuryandari - 2012 - Virtual interaction at virtual environment applied for Augmented Reality.pdf:pdf},
isbn = {978-1-4673-1816-7},
keywords = {3D virtual computer,AR,Augmented Reality,Computers,Educational institutions,HCI,Hidden Markov models,Human Computer Interaction,Human computer interaction,Humans,Three dimensional displays,Virtual Interaction,Virtual environments,augmented reality,computer technology,geometry model,human computer interaction,human interaction,image processing,information technology,interaction technique,virtual environment,virtual interaction},
month = {apr},
pages = {1--7},
publisher = {IEEE},
shorttitle = {Cloud Computing and Social Networking (ICCCSN), 20},
title = {{Virtual interaction at virtual environment applied for Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6215734},
year = {2012}
}
@inproceedings{Valkov2012,
abstract = {Traditionally, interaction techniques for virtual reality applications are implemented in a proprietary way on specific target platforms, e. g., requiring specific hardware, physics or rendering libraries, which withholds reusability and portability. Though hardware abstraction layers for numerous devices are provided by multiple virtual reality libraries, they are usually tightly bound to a particular rendering environment. In this paper we introduce Viargo - a generic virtual reality interaction library, which serves as additional software layer that is independent from the application and its linked libraries, i. e., a once developed interaction technique, such as walking with a head-mounted display or multi-touch interaction, can be ported to different hard- or software environments with minimal code adaptation. We describe the underlying concepts and present examples on how to integrate Viargo in different graphics engines, thus extending proprietary graphics libraries with a few lines of code to easy-to-use virtual reality engines.},
author = {Valkov, Dimitar and Bolte, Benjamin and Bruder, Gerd and Steinicke, Frank},
booktitle = {2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)},
doi = {10.1109/SEARIS.2012.6231177},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Valkov et al/2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)/Valkov et al. - 2012 - Viargo - A generic virtual reality interaction library.pdf:pdf},
isbn = {978-1-4673-1248-6},
keywords = {Cameras,Engines,Hardware,Libraries,Rendering (computer graphics),Synchronization,Virtual reality library,abstraction layers,generic virtual reality interaction library,graphics engines,hardware abstraction layers,interaction metaphors,libraries,linked libraries,minimal code adaptation,proprietary graphics libraries,rendering (computer graphics),rendering environment,software layer,software portability,software reusability,viargo,virtual reality},
month = {mar},
pages = {23--28},
publisher = {IEEE},
shorttitle = {Software Engineering and Architectures for Realtim},
title = {{Viargo - A Generic Virtual Reality Interaction Library}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6231177},
year = {2012}
}
@article{Stone1994,
author = {Stone, Linda M and Erickson, Thomas and Bederson, Benjamin B and Rothman, Peter and Muzzy, Raymond},
doi = {10.1109/VISUAL.1994.346286},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Stone et al/Unknown/Visualizing data- is virtual reality the key.pdf:pdf},
pages = {410--413},
title = {{Visualizing Data: Is Virtual Reality the Key?}},
year = {1994}
}
@book{Vaishnavi2008,
address = {Boston, MA},
author = {Vaishnavi, Vijay K. and {Kuechler Jr.}, William},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Vaishnavi, Kuechler Jr/Unknown/Vaishnavi, Kuechler Jr. - 2008 - Design Science Research Methods and Patterns Innovating Information and Communication Technology.pdf:pdf},
isbn = {9781420059328},
keywords = {Design Research,ICT,Method},
mendeley-tags = {Design Research,ICT,Method},
pages = {244},
publisher = {Auerbach Publications},
title = {{Design Science Research Methods and Patterns: Innovating Information and Communication Technology}},
year = {2008}
}
@article{Paradox2014,
author = {{Paradox Interactive AB}},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Paradox Interactive AB/Unknown/Paradox Interactive AB - 2014 - Cities Skylines - Fire Safety Info View.png:png},
title = {{Cities: Skylines - Fire Safety Info View}},
url = {http://www.skylineswiki.com/File:Fire{\_}Safety{\_}Info{\_}View{\_}SS.png},
year = {2014}
}
@misc{Gartner2015,
author = {Gartner},
title = {{Gartner's 2015 Hype Cycle for Emerging Technologies Identifies the Computing Innovations That Organizations Should Monitor}},
url = {https://www.gartner.com/newsroom/id/3114217},
urldate = {2016-05-08},
year = {2015}
}
@article{Safrudin2015,
author = {Safrudin, Niz and Fay, Maria and Changa, Avinash and {De Wit}, Benjamin},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Safrudin et al/360° - the Business Transformation Journal/Safrudin et al. - 2015 - Game Changing Digital Technologies Sharing the Mobile Virtual Reality Experience.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {360° - the Business Transformation Journal},
number = {13},
pages = {7--19},
title = {{Game Changing Digital Technologies: Sharing the Mobile Virtual Reality Experience}},
year = {2015}
}
@article{Myers1998,
abstract = {An abstract is not available.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Myers, Brad A.},
doi = {10.1145/274430.274436},
eprint = {1111.6189v1},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Myers/Interactions/Myers - 1998 - A brief history of human-computer interaction technology.pdf:pdf},
isbn = {1072-5520},
issn = {10725520},
journal = {Interactions},
number = {march+april},
pages = {44--54},
pmid = {20876008},
title = {{A Brief History of Human-Computer Interaction Technology}},
year = {1998}
}
@article{Whyte1999,
abstract = {Virtual reality (VR) packages offer good visualization capabilities but inadequate facilities for either internal data management or data exchange with other packages. The potential usefulness of VR packages for industrial and business applications is limited by their lack of support for the manipulation of specialist information. Their generic nature cannot retain the complex semantics and syntax of industrial information. Within the iterative process of building design and visualization, support is required for construction industry data, which is ordered in a complex and domain specific manner. Improved transfer of data from specialist building design tools to virtual reality has been investigated in previous research, but in this paper it is argued that data transfer is not enough. Virtual reality techniques need to become available within the specialist buildings design tools and alter the interface to such applications},
author = {Whyte, Jennifer and Bouchlaghem, Dino and Thorpe, Tony},
doi = {10.1109/IV.1999.781544},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Whyte, Bouchlaghem, Thorpe/Proceedings of the International Conference on Information Visualisation/Visualization and information- a building design perspective.pdf:pdf},
isbn = {0769502105},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
pages = {104--109},
title = {{Visualization and Information: A Building Design Perspective}},
volume = {1999-Janua},
year = {1999}
}
@article{Vaishnavi2004,
abstract = {This page is dedicated to design science research in Information Systems (IS). Design science research is yet another "lens" or set of synthetic and analytical techniques and perspectives (complementing the Positivist and Interpretive perspectives) for performing research in IS. Design science research involves the creation of new knowledge through design of novel or innovative artifacts (things or processes that have or can have material existence) and analysis of the use and/or performance of such artifacts along with reflection and abstraction—to improve and understand the behavior of aspects of Information Systems. Such artifacts include—but certainly are not limited to—algorithms (e.g. for information retrieval), human/computer interfaces, and system design methodologies or languages. Design science researchers can be found in many disciplines and fields, notably Engineering and Computer Science; they use a variety of approaches, methods and techniques. In Information Systems, following a number of years of a general shift in IS research away from technological to managerial and organizational issues, an increasing number of observers are calling for a return to an exploration of the "IT" that underlies all IS research (Orlikowski and Iacono, 2001) thus underlining the need for IS design science research.},
author = {Vaishnavi, Vijay and Kuechler, William},
doi = {10.1007/978-1-4419-5653-8},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Vaishnavi, Kuechler/Unknown/Vaishnavi, Kuechler - 2004 - Design Science Research in Information Systems.pdf:pdf},
isbn = {0849337968},
issn = {02767783},
pages = {45},
pmid = {12581935},
title = {{Design Science Research in Information Systems}},
url = {http://www.desrist.org/design-research-in-information-systems/},
year = {2004}
}
@book{Saunders2009,
abstract = {A comprehensive introduction to research methods in business for students planning or undertaking a dissertation or extensive research project in business and management.The fifth edition of Research Methods for Business Students brings the theory, philosophy and techniques of research to life and enables students to understand the practical relevance of the research methods. A highly accessible style and logical structure have made this the Āstudent choice' and run-away market leader.The book is written for students on undergraduate and postgraduate degree programmes in business, or business-related disciplines.The following online resources support the text: For Students: self-assessment questions, glossary, revision ĀflashcardsĀ, tutorials for SPSS and NVivo, plus Smarter Online Searching GuideFor Instructors: teaching manual, powerpoint slides, testbank},
address = {Essex},
author = {Saunders, Mark and Lewis, Philip and Thornhill, Adrian},
booktitle = {Research methods for business students},
edition = {5},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Saunders, Lewis, Thornhill/Research methods for business students/Saunders, Lewis, Thornhill - 2009 - Research Methods for Business Students.pdf:pdf},
isbn = {978-0-273-71686-0},
issn = {0047-2875},
pages = {649},
pmid = {15573286},
publisher = {Pearson Education Limited},
title = {{Research Methods for Business Students}},
year = {2009}
}
@misc{UBSAG2014,
author = {{UBS AG}},
title = {{Master of Swiss Web 2014}},
url = {https://www.ubs.com/ch/en/awards/best-of-swiss-web-2014.html},
urldate = {2016-12-22},
year = {2014}
}
@article{Steed2006,
abstract = {Selection is one of the fundamental building blocks of all interactive virtual environment systems. Selection is the ability of the user to specify which object, or sub-part of an object in the environment, is the target for subsequent actions. Examples include selecting 3D buttons thus invoking an action or selecting a target upon which an action will occur. Selection is also an implicit or explicit part of manipulation techniques. In a virtual environment selection can be performed in many different ways. In this paper we develop a generalized model of how interaction is and could be performed in virtual environments using 3D gestures. The purpose of this model is to highlight some potential areas for development and evaluation of novel selection techniques. The model is based on an analysis of the complexity of selection. We develop a model for selection that is based on time-varying scalar fields (TVSFs) that encompasses a very broad range of existing techniques. This model will be abstract, in that a direct implementation will be prohibitively complex, but we show how some standard implementation strategies are good approximations to the formal model.},
author = {Steed, Anthony},
doi = {10.1109/VR.2006.134},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Steed/3D User Interfaces (3DUI'06)/Steed - 2006 - Towards a General Model for Selection in Virtual Environments.pdf:pdf},
isbn = {1-4244-0225-5},
journal = {3D User Interfaces (3DUI'06)},
keywords = {3D interaction,selection,virtual environments},
pages = {103--110},
title = {{Towards a General Model for Selection in Virtual Environments}},
year = {2006}
}
@inproceedings{Pfeiffer2008,
abstract = {Interaction in conversational interfaces strongly relies on the system's capability to interpret the user's references to objects via deictic expressions. Deictic gestures, especially pointing gestures, provide a powerful way of referring to objects and places, e.g., when communicating with an embodied conversational agent in a virtual reality environment. We highlight results drawn from a study on pointing and draw conclusions for the implementation of pointing-based conversational interactions in partly immersive virtual reality.},
author = {Pfeiffer, Thies and Latoschik, Marc E. and Wachsmuth, Ipke},
booktitle = {2008 IEEE Virtual Reality Conference},
doi = {10.1109/VR.2008.4480801},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Pfeiffer, Latoschik, Wachsmuth/2008 IEEE Virtual Reality Conference/Pfeiffer, Latoschik, Wachsmuth - 2008 - Conversational Pointing Gestures for Virtual Reality Interaction Implications from an Empirical.pdf:pdf},
isbn = {978-1-4244-1971-5},
keywords = {Collaborative work,Computer graphics,Context modeling,Data mining,Games,H.5.2 [Information Interfaces and Presentation]: U,Humans,I.3.6 [Computer Graphics]: Methodology and Techniq,Object detection,Shape,Tracking,Virtual reality,conversational interfaces,conversational pointing gestures,deictic expressions,deictic gestures,embodied conversational agent,virtual reality,virtual reality interaction},
pages = {281--282},
publisher = {IEEE},
shorttitle = {Virtual Reality Conference, 2008. VR '08. IEEE},
title = {{Conversational Pointing Gestures for Virtual Reality Interaction: Implications from an Empirical Study}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4480801},
year = {2008}
}
@inproceedings{Stauffer2016,
abstract = {The primary Visual Information Seeking Mantra (VISM) [1] has been extended overcoming known weaknesses [2], [3] regarding complex information handling. An improved framework, the so called Visual Information Seeking Mantra 2.0 (VISM 2.0), is derived supporting formerly missing tasks and improving existing ones. The proposed framework is furthermore embedded in a User-Centered Development (UCD) process in order to support a (front-end) developer throughout the whole development process of an information system.},
author = {Stauffer, Michael and Ryter, Remo and Dornberger, Rolf and Hill, Darjan},
booktitle = {The 7th International Multi-Conference on Complexity, Informatics and Cybernetics},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Stauffer et al/The 7th International Multi-Conference on Complexity, Informatics and Cybernetics/Stauffer et al. - 2016 - A review and extension of the Visual Information Seeking Mantra (VISM).pdf:pdf},
pages = {4},
title = {{A review and extension of the Visual Information Seeking Mantra (VISM)}},
year = {2016}
}
@misc{HTCCorp2016,
author = {{HTC Corporation}},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/HTC Corporation/Unknown/HTC Corporation - 2016 - Vive User Guide.pdf:pdf},
pages = {1--42},
publisher = {HTC Corporation},
title = {{Vive User Guide}},
url = {http://dl4.htc.com/web{\_}materials/Manual/Vive/Vive{\_}User{\_}Guide.pdf},
year = {2016}
}
@inproceedings{Khundam2015,
abstract = {Virtual reality (VR) has become a very popular technology in recent years, which used in the field of multimedia for various purposes. One of the applications that widely used for simulating physical presence in the real world is walk-through VR. In the walk-through VR system will generate simulation character or avatar for user which able to control movement, especially first person movement walk-through in VR with many input devices. In this paper, we present a human - computer interaction with the connection of Oculus Rift and Leap Motion new technological devices for VR. Oculus Rift is VR headset or head - mounted display devices that have a small display optic in front of each eye. Oculus Rift can track head movement and change view point follow it. Leap Motion is in - air controller that can track hand gesture of the user. The combination of them will make users feel like immerse to VR. Users can move avatar any way in VR by their hand interact through the system via these devices. We introduce a new interactive hand gesture system with palm normal for control steering develop by the game engine Unity3D applies synchronization of Oculus Rift and Leap Motion. Our design and development method will allow users to adjust moving speed follows the hand gesture and the range of the user's hand that make a smoothly moving with acceleration.},
author = {Khundam, Chaowanan},
booktitle = {2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
doi = {10.1109/JCSSE.2015.7219818},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Khundam/2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)/07219818.pdf:pdf},
isbn = {978-1-4799-1966-6},
keywords = {Avatars,Computers,Engines,Game Engine,Games,Head - Mounted Display,Headphones,Human - Computer Interaction,In - Air Controller,Leap Motion new technological devices,Oculus Rift,Three-dimensional displays,Tracking,Unity3D game engine,Virtual Reality,avatar,avatars,digital simulation,first person movement control,gesture recognition,hand gesture interaction,human computer interaction,human-computer interaction,motion control,multimedia,palm normal,physical presence simulation,simulation character,small display optic,virtual reality,walk-through VR},
month = {jul},
pages = {325--330},
publisher = {IEEE},
shorttitle = {Computer Science and Software Engineering (JCSSE),},
title = {{First person movement control with palm normal and hand gesture interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7219818},
year = {2015}
}
@article{Anthes,
abstract = {In the past three years, the so-called second wave of Virtual Reality (VR) has brought us a vast amount of new dis- plays and input devices. Not only new hardware has entered the consumer market providing affordable pricing models but also completely new technologies are being designed and developed. Additionally new concepts for handling existing problems on the hardware and software side of the VR technology are constantly being introduced. This software and hardware development is mainly lead by enthusiasts interested in the domain of VR opposed to the established scientific community, which already partially makes use of the newly available technology. Besides Head-Mounted Displays (HMDs), either cable-based or mobile, other devices like haptics devices, controllers, vests, omnidirectional tread- mills, tracking technologies, as well as optical scanners for gesture-based interaction are gaining importance in the field of commodity VR. Most of these technologies are already precise and robust enough to be used for professional operation and scientific experiments. The topics discussed are the common issues with the new tech- nologies including the approaches to solve them as for example motion-to-photon latency, barrel distortion, and low-persistence displays. Additionally an in-depth analysis of the available solutions expected to hit the market is provided. A taxonomy categorising the current developments with the chosen imple- mentation approaches will be given. The paper analyses the state of technological advancements in the field and provides an extensive overview on the current development considering the upcoming devices and the advancements from the software side.},
author = {Anthes, Christoph and Garc{\'{i}}a-Hern{\'{a}}ndez, Rub{\'{e}}n Jes{\'{u}}s and Kranzlm{\"{u}}ller, Markus and {Wiedemann Dieter}},
file = {::},
journal = {2016 IEEE Aerospace Conference, At Big Sky, Montana, United States},
title = {{State of the Art of Virtual Reality Technology}}
}
@inproceedings{Chun2015,
abstract = {The computers nowadays are powerful enough to make the virtual reality technology more practical. Virtual reality is expected to have a bright future due to the rise of several virtual reality head mounted device such as low cost Google Cardboard, Samsung Gear VR, Oculus, HTC Vive and many others. Since virtual reality had been growing fast in this few years thus it is necessary to explore new approaches for user to interact with the virtual reality more naturally. It is an important research in HCI to make the interactions with computers to be as natural as the interaction between humans. One of the approaches is to allow user to interact with the virtual reality through gesture and speech input. This paper presents a virtual reality environment with multimodal interaction technique. It allows user to interact with the virtual reality system with the static and stroke hand gesture along with speech. This multimodal interaction technique is able to perform few functions such as select, move, scale, rotate, copy, mirror, delete, check the shape, check and change the colour of an object.},
author = {Chun, Lam Meng and Arshad, Haslina and Piumsomboon, Thammathip and Billinghurst, Mark},
booktitle = {2015 International Conference on Electrical Engineering and Informatics (ICEEI)},
doi = {10.1109/ICEEI.2015.7352470},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Chun et al/2015 International Conference on Electrical Engineering and Informatics (ICEEI)/Chun et al. - 2015 - A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual.pdf:pdf},
isbn = {9781467373197},
keywords = {Virtual Reality,gesture,hand gesture and speech,human computer interaction,interaction,multimodal,natural interaction,new,speech,speech recognition},
mendeley-tags = {Virtual Reality,gesture,multimodal,new,speech,speech recognition},
month = {aug},
pages = {59--64},
publisher = {IEEE},
title = {{A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=7352470},
year = {2015}
}
@article{Sun2011,
abstract = {The study constructs joyful Web 3D virtual situational learning materials with the perspectives of learners, and takes Tainan Confucian Temple as an example to allow the learners to learn and experience freely in virtual reality. The joyful learning environment is presented in the virtual situation through vivid text, sound, a guided picture tour, and a game-like learning mechanism. Different from the passive “knowledge giving model” in the past virtual situational learning system, the “joyful learning component” is integrated into the virtual situation to change knowledge imparting from “passive” to “active” to effectively enhance the learning motivation of learners and improve their learning effectiveness. Finally, grade 5 students are applied as the experimental subjects in the study analysis focusing on the satisfaction of learning system application and the significance difference of the learning result before and after the system is applied. The study result shows that the application of a joyful virtual situation can indeed achieve the same effectiveness of on- site experimental learning.},
author = {Sun, Koun-Tem and Chan, Hsin-Te and Yin, Tai-lin},
file = {:D$\backslash$:/Dropbox/Studium/MENDELEY/File Organizer/Sun, Chan, Yin/The 7th International Conference on Digital Content, Multimedia Technology and its Applications/Sun, Chan, Yin - 2011 - A case study on building Web3D virtual reality and its applications to j.pdf:pdf},
isbn = {9788988678466},
journal = {The 7th International Conference on Digital Content, Multimedia Technology and its Applications},
keywords = {Electronic learning,Games,Learning systems,Solid modeling,Tainan Confucian Temple,Three dimensional displays,Web3D virtual reality building,computer aided instruction,e-learning,game-like learning mechanism,joyful Web 3D virtual situational learning materia,joyful learning component,knowledge giving model,learning,on-site experimental learning,situational teaching,virtual reality,virtual situational learning system},
mendeley-tags = {e-learning,learning,situational teaching},
month = {aug},
pages = {49--54},
title = {{A case study on building Web3D virtual reality and its applications to joyful learning}},
url = {http://ieeexplore.ieee.org/ielx5/6008798/6016618/06016630.pdf?tp={\&}arnumber=6016630{\&}isnumber=6016618},
year = {2011}
}
