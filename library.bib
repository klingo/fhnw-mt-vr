Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@book{Vaishnavi2007,
address = {Boston, MA},
author = {Vaishnavi, Vijay K. and {Kuechler Jr.}, William},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Vaishnavi, Kuechler Jr/Unknown/design-science-research-in-information-systems.pdf:pdf},
isbn = {9781420059328},
keywords = {Design Research,ICT,Method},
mendeley-tags = {Design Research,ICT,Method},
pages = {248},
publisher = {Auerbach Publications},
title = {{Design Science Research Methods and Patterns: Innovating Information and Communication Technology}},
year = {2007}
}
@article{Walczak2002,
abstract = {A new method of dynamic generation of virtual scenes for use in$\backslash$nInternet virtual reality applications is presented. The virtual scenes$\backslash$nare dynamically generated from virtual scene models coded in a$\backslash$nhigh-level XML-based language called X-VRML. The language consists of a$\backslash$nset of XML tags introducing new elements to programming of virtual$\backslash$nreality. These new elements include object-orientation, access to$\backslash$ndatabases, and programming techniques known from procedural languages$\backslash$nlike variables, conditions, and loops. The X-VRML language overcomes the$\backslash$nmain limitations of current virtual reality systems. Use of X-VRML$\backslash$nsimplifies the code of virtual scene models, allows retrieval of data$\backslash$nfrom databases, selection of virtual scene contents, customization of$\backslash$nvirtual scenes, and efficient coding of elements that have repetitive$\backslash$nstructure. Applications of X-VRML include on-line data visualization,$\backslash$ngeographical information systems, scientific visualization, virtual$\backslash$ngames, and e-commerce applications such as virtual shops},
author = {Walczak, K. and Cellary, W.},
doi = {10.1109/SAINT.2002.994479},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Walczak, Cellary/Proceedings - 2002 Symposium on Applications and the Internet, SAINT 2002/Walczak, Cellary - 2002 - X-VRML-XML based modeling of virtual reality.pdf:pdf},
isbn = {0769514472},
journal = {Proceedings - 2002 Symposium on Applications and the Internet, SAINT 2002},
keywords = {Content based retrieval,Data visualization,Information retrieval,Internet,Layout,Object oriented databases,Object oriented programming,Virtual reality,Visual databases,XML},
pages = {204--211},
title = {{X-VRML-XML based modeling of virtual reality}},
year = {2002}
}
@inproceedings{Nguyen2012a,
abstract = {Bus is public means to travel in several cities. Traditional maps provide with the information of bus routes that passengers may use to design a travel from a place to another. It is difficult for them to obtain an appropriate route because of the lack of the information of time on the traditional maps. Some web sites enable passengers to take bus but they do not support passengers to have more diverse selections. In this paper, buses are considered as moving objects. Mathematically, movements of objects are the mappings (functions) from times to locations. In 3-D Cartesian coordinate systems, space-time cubes, which are called temporal maps in this paper, are models representing movements in spatio-temporal domain. A bus route on a traditional map is the curve connecting the spatial positions where the bus visits, from the departure station to the arrival. A bus trip is a bus route included time. It is represented on temporal maps. With the visualization of spatio-temporal data of bus trips on temporal maps, passengers may mark out bus trips for their more appropriate travels. This article implemented visualization tools for the design of bus travels on temporal maps.},
author = {Nguyen, Hong Thi and Duong, Chi Kim Thi and Bui, Tha Thi and Tran, Phuoc Vinh},
booktitle = {2012 International Conference on Control, Automation and Information Sciences, ICCAIS 2012},
doi = {10.1109/ICCAIS.2012.6466625},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Nguyen et al/2012 International Conference on Control, Automation and Information Sciences, ICCAIS 2012/Nguyen et al. - 2012 - Visualization of spatio-temporal data of bus trips.pdf:pdf},
isbn = {9781467308137},
pages = {392--397},
title = {{Visualization of spatio-temporal data of bus trips}},
year = {2012}
}
@inproceedings{Deligiannidis2003,
abstract = {The Industrial and Manufacturing Engineering Department at Wichita State University is developing an integrated set of virtual reality models of a manufacturing line of Boeing Wichita. The purpose of this research is to help Boeing and other aerospace manufacturers improve their manufacturing operations. In our virtual environment, a fully immersed person is working on a specific task and several (up to 20) outsiders (participants) observe the fully, immersed person and would like to comment and affect the fully immersed person's work. The lack of interaction between the fully immersed person and the participants is the most critical issue. The current communication technique used is vocal instruction, which is distracting to everyone. This paper presents a technique in which the fully immersed person and the participants can interact using a second camera directed for a third person's view of the environment. This technique attempts to provide the best of both worlds (first and third person views) so the formerly passive participants can become more immersed in the environment.},
author = {Deligiannidis, L. and Whitman, L.},
booktitle = {IEEE Virtual Reality, 2003. Proceedings.},
doi = {10.1109/VR.2003.1191159},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Deligiannidis, Whitman/IEEE Virtual Reality, 2003. Proceedings/Deligiannidis, Whitman - 2003 - User interaction in a power-wall based virtual reality environment.pdf:pdf},
isbn = {0-7695-1882-6},
issn = {1087-8270},
keywords = {Aerospace engineering,Aerospace industry,Boeing,Cameras,Control systems,Manufacturing industries,Navigation,Power engineering and energy,Virtual environment,Virtual manufacturing,Virtual reality,aerospace industry,aerospace manufacturers,camera,computer integrated manufacturing,human factors,manufacturing line,power-wall based virtual reality environment,user interaction,user interfaces,virtual reality,vocal instruction},
pages = {279--280},
publisher = {IEEE Comput. Soc},
shorttitle = {Virtual Reality, 2003. Proceedings. IEEE},
title = {{User interaction in a power-wall based virtual reality environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1191159},
year = {2003}
}
@book{Saunders2009,
abstract = {A comprehensive introduction to research methods in business for students planning or undertaking a dissertation or extensive research project in business and management.The fifth edition of Research Methods for Business Students brings the theory, philosophy and techniques of research to life and enables students to understand the practical relevance of the research methods. A highly accessible style and logical structure have made this the Āstudent choice' and run-away market leader.The book is written for students on undergraduate and postgraduate degree programmes in business, or business-related disciplines.The following online resources support the text: For Students: self-assessment questions, glossary, revision ĀflashcardsĀ, tutorials for SPSS and NVivo, plus Smarter Online Searching GuideFor Instructors: teaching manual, powerpoint slides, testbank},
address = {Essex},
author = {Saunders, Mark and Lewis, Philip and Thornhill, Adrian},
booktitle = {Research methods for business students},
edition = {5},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Saunders, Lewis, Thornhill/Research methods for business students/Research{\_}Methods{\_}for{\_}Business{\_}Students{\_}{\_}5th{\_}Edition.pdf:pdf},
isbn = {978-0-273-71686-0},
issn = {0047-2875},
pages = {649},
pmid = {15573286},
publisher = {Pearson Education Limited},
title = {{Research Methods for Business Students}},
year = {2009}
}
@article{Stone1994,
author = {Stone, Linda M and Erickson, Thomas and Bederson, Benjamin B and Rothman, Peter and Muzzy, Raymond},
doi = {10.1109/VISUAL.1994.346286},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Stone et al/Unknown/Stone et al. - 1994 - Visualizing Data Is Virtual Reality the Key.pdf:pdf},
pages = {410--413},
title = {{Visualizing Data : Is Virtual Reality the Key ?}},
year = {1994}
}
@book{Adapa2011,
abstract = {The traditional mode of delivering products and services by banks to the consumers' is through a single distribution channel and that is physical bank branches. Financial services industry is metamorphosing due to the advent of internet, rapid technological evolutions, deregulation, globalization as well as the impact of changing competitive and regulatory forces. In order to cope with the quick changes in the business scenario, banks started to rely on distribution channels as an alternative strategy for differentiation and gaining further competitive advantage. The abovementioned paved way for the development of the ebanking phenomena. This chapter attempts to provide a comprehensive explanation of what ebanking is, the evolution of ebanking, existing trends of ebanking in developed, developing and newly industrialized nations, future directions for further possible research and concluding remarks. The content provided in this chapter would be useful for existing and potential banks to better understand the global ebanking trends and thus aid in the effective formulation of channel management strategies and reap the benefits out of it.},
author = {Adapa, Sujana},
booktitle = {E-Banking and Emerging Multidisciplinary Processes},
doi = {10.4018/978-1-61520-635-3.ch001},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Adapa/E-Banking and Emerging Multidisciplinary Processes/Adapa - 2011 - Global E-Banking Trends Evolution, Challenges and Opportunities.pdf:pdf},
isbn = {9781615206353},
pages = {1--16},
publisher = {IGI Global},
title = {{Global E-Banking Trends: Evolution, Challenges and Opportunities}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-635-3.ch001},
year = {2011}
}
@article{Moore1999,
author = {Moore, C W and McClurg, D C and Soreide, N N and Hermann, A J and Lascara, C M and Wheless, G H},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Moore et al/Unknown/Moore et al. - 1999 - Exploring 3-dimensional oceanographic data sets on the Web using virtual reality modeling language.pdf:pdf},
number = {Idl},
pages = {1501--1503},
title = {{Exploring 3-dimensional oceanographic data sets on the Web using virtual reality modeling language}},
volume = {3},
year = {1999}
}
@inproceedings{Rautaray2011,
abstract = {Hand gesture recognition systems for virtual reality applications provides the users an enhanced interaction experience as it integrates the virtual and the real world object. Growth in virtual environments based upon computer systems and development of user interfaces influence the changes in the Human-Computer Interaction (HCI). Gesture recognition based interaction interface, endow with more realistic and immersive interaction compared to the traditional devices. The system enables a physically realistic mode of interaction to the virtual environment. The Hand gesture recognition system based interface proposed and implemented in this paper consists of a detection, tracking and recognition module. For the implementation of these modules various image processing algorithms as Camshift, Lucas Kanade, Haar like features etc has been employed. Comprehensive user acceptability has been considered to exhibit the accuracy, usefulness and ease of use to the proposed and implemented hand gesture recognition system. Hand gesture communication based vocabulary offers many variations ranging from simple action of using our finger to point at to using hands for moving objects around to the rather complex one like expression of the feelings. The proposed hand gesture recognition system offers intensions to traditional input devices for interaction with the virtual environments. The gesture based interaction interface being proposed here can be substantially applied towards many applications like Virtual Reality, Sign Language and Games. Though the present paper considered games as the application domain.},
author = {Rautaray, Siddharth S. and Agrawal, Anupam},
booktitle = {2011 International Conference on Multimedia, Signal Processing and Communication Technologies},
doi = {10.1109/MSPCT.2011.6150485},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Rautaray, Agrawal/2011 International Conference on Multimedia, Signal Processing and Communication Technologies/Rautaray, Agrawal - 2011 - Interaction with virtual game through hand gesture recognition.pdf:pdf},
isbn = {978-1-4577-1107-7},
keywords = {Camshift image processing algorithms,Games,Gesture recognition,Haar like features,Human computer interaction,Humans,Lucas Kanade image processing algorithms,Multimedia communication,Tracking,Virtual environments,computer games,computer systems,gesture recognition,gesture recognition based interaction interface,hand gesture communication based vocabulary,hand gesture recognition systems,human computer interaction,human-computer interaction,palmprint recognition,sign language,user interfaces,virtual game,virtual reality},
month = {dec},
pages = {244--247},
publisher = {IEEE},
shorttitle = {Multimedia, Signal Processing and Communication Te},
title = {{Interaction with virtual game through hand gesture recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6150485},
year = {2011}
}
@inproceedings{He2009,
abstract = {The growing complexity of virtual reality simulations and the inclusion of a greater range and number of events and interactions in such simulations precipitates the need for the recording of these events to allow their subsequent viewing, discussion and perhaps modification. Furthermore, storage of such recordings in a format defined by an international standard allows their easy use and accessibility as well as distribution. This paper presents a framework for MPEG-4 based recording and replay of virtual reality sessions.},
author = {He, Zhiyong and Zhao, Chunsheng},
booktitle = {2009 International Conference on Communication Software and Networks},
doi = {10.1109/ICCSN.2009.80},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/He, Zhao/2009 International Conference on Communication Software and Networks/He, Zhao - 2009 - A Recording Method of Virtual Reality Interaction.pdf:pdf},
isbn = {978-0-7695-3522-7},
keywords = {Collaboration,Computational modeling,Computer science,Computer simulation,Discrete event simulation,Disk recording,Interaction,Layout,MPEG 4 Standard,MPEG-4,MPEG-4 based recording,Recording,Streaming media,Virtual realit,Virtual reality,audio recording,multimedia communication,recording method,video recording,virtual reality,virtual reality interaction},
pages = {666--669},
publisher = {IEEE},
shorttitle = {Communication Software and Networks, 2009. ICCSN '},
title = {{A Recording Method of Virtual Reality Interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5076938},
year = {2009}
}
@article{Drouhard2015,
abstract = {In this paper, we propose strategies and objectives for immersive data visualization with applications in materials science using the Oculus Rift virtual reality headset. We provide background on currently available analysis tools for neutron scattering data and other large-scale materials science projects. In the context of the current challenges facing scientists, we discuss immersive virtual reality visualization as a potentially powerful solution. We introduce a prototype immersive visual- ization system, developed in conjunction with materials scientists at the Spallation Neutron Source, which we have used to explore large crystal structures and neutron scattering data. Finally, we offer our perspective on the greatest challenges that must be addressed to build effective and intuitive virtual reality analysis tools that will be useful for scientists in a wide range of fields},
author = {Drouhard, Margaret and Steed, Chad A and Hahn, Steven and Proffen, Thomas and Daniel, Jamison and Matheson, Michael},
doi = {10.1109/BigData.2015.7364040},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Drouhard et al/Unknown/Drouhard et al. - 2015 - Immersive Visualization for Materials Science Data Analysis using the Oculus Rift.pdf:pdf},
isbn = {978-1-4799-9926-2},
pages = {2453--2461},
title = {{Immersive Visualization for Materials Science Data Analysis using the Oculus Rift}},
year = {2015}
}
@article{Jamieson2007,
abstract = {As Terabyte datasets become the norm, the focus has shifted away from our ability to produce and store ever larger amounts of data, onto its utilization. It is becoming increasingly difficult to gain meaningful insights into the data produced. Also many forms of the data we are currently producing cannot easily fit into traditional visualization methods. This paper presents a new and novel visualization technique based on the concept of a Data Forest. Our Data Forest has been designed to be used with virtual reality (VR) as its presentation method. VR is a natural medium for investigating large datasets. Our approach can easily be adapted to be used in a variety of different ways, from a stand alone single user environment to large multi-user collaborative environments. A test application is presented using multi-dimensional data to demonstrate the concepts involved.},
author = {Jamieson, Ronan and Alexandrov, Vassil},
doi = {10.1109/IV.2007.9},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Jamieson, Alexandrov/Proceedings of the International Conference on Information Visualisation/Jamieson, Alexandrov - 2007 - A data forest Multi-dimensional visualization.pdf:pdf},
isbn = {0-7695-2900-3},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
keywords = {Data forest,Immersive visualization,Multi-dimensional data,VieGen,Virtual reality},
pages = {293--298},
title = {{A data forest: Multi-dimensional visualization}},
year = {2007}
}
@inproceedings{Chun2015,
abstract = {The computers nowadays are powerful enough to make the virtual reality technology more practical. Virtual reality is expected to have a bright future due to the rise of several virtual reality head mounted device such as low cost Google Cardboard, Samsung Gear VR, Oculus, HTC Vive and many others. Since virtual reality had been growing fast in this few years thus it is necessary to explore new approaches for user to interact with the virtual reality more naturally. It is an important research in HCI to make the interactions with computers to be as natural as the interaction between humans. One of the approaches is to allow user to interact with the virtual reality through gesture and speech input. This paper presents a virtual reality environment with multimodal interaction technique. It allows user to interact with the virtual reality system with the static and stroke hand gesture along with speech. This multimodal interaction technique is able to perform few functions such as select, move, scale, rotate, copy, mirror, delete, check the shape, check and change the colour of an object.},
author = {Chun, Lam Meng and Arshad, Haslina and Piumsomboon, Thammathip and Billinghurst, Mark},
booktitle = {2015 International Conference on Electrical Engineering and Informatics (ICEEI)},
doi = {10.1109/ICEEI.2015.7352470},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Chun et al/2015 International Conference on Electrical Engineering and Informatics (ICEEI)/Chun et al. - 2015 - A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment.pdf:pdf},
isbn = {9781467373197},
keywords = {Virtual Reality,gesture,hand gesture and speech,human computer interaction,interaction,multimodal,natural interaction,new,speech,speech recognition},
mendeley-tags = {Virtual Reality,gesture,multimodal,new,speech,speech recognition},
month = {aug},
pages = {59--64},
publisher = {IEEE},
title = {{A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=7352470},
year = {2015}
}
@inproceedings{Ariyana2012,
abstract = {Information technology currently supports the development of human interaction with virtual environment, this development will continue in developing in the form of Human Computer Interaction (HCI). In this study, how the environment 3D virtual computer should be able to recognize human hand as part as virtual object, so it can interact with virtual environment. HCI is a study in which the relationship between humans and computing technology and how computers are designed for easy to use by human, more practical and more intuitive. HCI emphasizes how human interaction with computer technology. This research is using interaction technique in virtual environment to interact between human hand and virtual object. Tracker is needed in virtual interaction by using Augmented Reality (AR), the problem that arise in AR is how to read marker, so it can display a virtual object that has been computed before, basically is how to read the geometry model of human hand, then the result from the processing of the human hand model geometry is used as a marker, so it can interact with a virtual environment on AR as one of the HCI model implementation. This process is intended for the movement of human hands that have been read as a virtual object can communicate virtually using image processing.},
author = {Ariyana, Y. and Wuryandari, A. I.},
booktitle = {2012 International Conference on Cloud Computing and Social Networking (ICCCSN)},
doi = {10.1109/ICCCSN.2012.6215734},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Ariyana, Wuryandari/2012 International Conference on Cloud Computing and Social Networking (ICCCSN)/Ariyana, Wuryandari - 2012 - Virtual interaction at virtual environment applied for Augmented Reality.pdf:pdf},
isbn = {978-1-4673-1816-7},
keywords = {3D virtual computer,AR,Augmented Reality,Computers,Educational institutions,HCI,Hidden Markov models,Human Computer Interaction,Human computer interaction,Humans,Three dimensional displays,Virtual Interaction,Virtual environments,augmented reality,computer technology,geometry model,human computer interaction,human interaction,image processing,information technology,interaction technique,virtual environment,virtual interaction},
month = {apr},
pages = {1--7},
publisher = {IEEE},
shorttitle = {Cloud Computing and Social Networking (ICCCSN), 20},
title = {{Virtual interaction at virtual environment applied for Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6215734},
year = {2012}
}
@article{Ware1994,
abstract = {An experiment is reported which tests whether network information is more effectively displayed in a three dimensional space than in a two dimensional space. The experimental task is to trace a path in a network and the experiment is carried out in 2D, in a 3D stereo view, in a 2D view with head coupled perspective, and in a 3D stereo view with head coupled perspective; this last condition creates a localized virtual reality display. The results show that the motion parallax obtained from the head coupling of perspective is more important than stereopsis in revealing structural information. Overall the results show that three times as much information can be perceived in the head coupled stereo view as in the 2D view},
author = {Ware, C. and Franck, G.},
doi = {10.1109/VL.1994.363621},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Ware, Franck/Proceedings of 1994 IEEE Symposium on Visual Languages/Ware, Franck - 1994 - Viewing a graph in a virtual reality display is three times as good as a 2D diagram.pdf:pdf},
isbn = {0-8186-6660-9},
issn = {10492615},
journal = {Proceedings of 1994 IEEE Symposium on Visual Languages},
keywords = {2D diagram,2D view,3D stereo view,Computer displays,Eyes,Glass,Head,Layout,Orthopedic surgery,Testing,Three dimensional displays,Two dimensional displays,Virtual reality,motion parallax,network information,stereopsis,structural information,virtual reality,virtual reality display,visual languages,visual perception},
pages = {182--183},
title = {{Viewing a graph in a virtual reality display is three times as good as a 2D diagram}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=363621},
year = {1994}
}
@inproceedings{Uchino2008,
abstract = {In this research, a dialog environment between human and virtual agent has been constructed. With the commercial off-the-shelf VR technologies, special devices such as data glove have to be used for the interaction. But this is difficult to manipulate objects. If there is a helper who has direct access to objects in a virtual space, we may ask him. The question, however, is how to communicate with the helper. This paper presents a solution to the question. The basic idea is to utilize speech recognition and gesture recognition systems. Experimental results have proved the effectiveness of the approach in terms of facilitating man-machine interaction and communication. The environment constructed in this research allows a user to communicate by talking and showing gestures to a personified agent in virtual environment. A user can use his/her finger to point at a virtual object and ask the agent to manipulate the virtual object.},
author = {Uchino, Shunji and Abe, Norihiro and Takada, Hiroshi and Yagi, Tetsuya and Taki, Hirokazu and He, Shoujie},
booktitle = {22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)},
doi = {10.1109/WAINA.2008.124},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Uchino et al/22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)/Uchino et al. - 2008 - Virtual Reality Interaction System between User and Avatar with Distributed Processing.pdf:pdf},
isbn = {978-0-7695-3096-3},
keywords = {Avatar,Avatars,Data gloves,Dialog Environment,Distributed processing,Fingers,Humans,Internet Meeting System,Man machine systems,Space technology,Speech recognition,Virtual Agent,Virtual environment,Virtual reality,avatar,avatars,dialog environment,distributed processing,gesture recognition systems,man-machine communication,man-machine interaction,personified agent,speech recognition,speech-based user interfaces,virtual agent,virtual object manipulation,virtual reality interaction system},
pages = {1034--1039},
publisher = {IEEE},
shorttitle = {Advanced Information Networking and Applications -},
title = {{Virtual Reality Interaction System between User and Avatar with Distributed Processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4483053},
year = {2008}
}
@article{Stephens2004,
abstract = {Knowledge discovery and visualisation are important techniques for discovering and understanding patterns in large data sets. The study presents the development of a three dimensional virtual reality model that assists the user to visually explore structures and relationships in the collected data. The three dimensional model uses a combination of nodes and paths to represent objects/actors and the strength/direction of the measured characteristic. Virtual reality provides the mechanism for manipulation of the developed model in real time. Specifically, we demonstrate the potential of this visual tool by having postgraduate students, organised into focus groups, engage in a knowledge discovery exercise with data collected in an academic work environment. The method adopted to convert the identified relationships into a virtual reality model is discussed, as well as some of the additional features that could be incorporated using such a method.},
author = {Stephens, G. and Handzic, M.},
doi = {10.1109/HICSS.2004.1265586},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Stephens, Handzic/37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the/Stephens, Handzic - 2004 - Knowledge discovery through visualising using virtual reality.pdf:pdf},
isbn = {0-7695-2056-1},
journal = {37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the},
number = {C},
pages = {1--10},
title = {{Knowledge discovery through visualising using virtual reality}},
volume = {00},
year = {2004}
}
@article{Cao2009,
abstract = {The paper attempts to focus on application method of virtual reality and take advantage of cognitive feature of virtual interface to explore animation interaction design. It aims at supplying feasible methods to realize simulation function of virtual reality and integrate the techniques required for creating digital actors and improve cognitive ability of human-machine interaction. This article describes motion technique and dynamic simulation of digital actor in animation area, and explores the problems and solutions including virtual animation in immersive virtual environments so as to validate the results of research on these topics.},
author = {Cao, Yali},
doi = {10.1109/CAIDCD.2009.5375379},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Cao/IEEE 10th International Conference on Computer-Aided Industrial Design {\&} Conceptual Design, 2009. CAID {\&} CD 2009/Cao - 2009 - Research on Interaction Design of Virtual Reality.pdf:pdf},
isbn = {9781424452682},
journal = {IEEE 10th International Conference on Computer-Aided Industrial Design {\&} Conceptual Design, 2009. CAID {\&} CD 2009.},
pages = {1340--1344},
title = {{Research on Interaction Design of Virtual Reality}},
year = {2009}
}
@article{Wann1996,
abstract = {Virtual reality (VR) has invaded the public's awareness through a series of media articles that have promoted it as a new and exciting form of computer interaction. We discuss the extent to which VR may be a useful tool in visualization and attempt to disambiguate the use of VR as a general descriptor for any three-dimensional computer presentation. The argument is presented that, to warrant the use of the term virtual environment (VE), the display should satisfy criteria that arise from the nature of human spatial perception. It directly follows, therefore, that perceptual criteria are the foundations of an effective VE display. We address the task of making a VE system easy to navigate, traverse and engage, by examining the ways in which three-dimensional perception and perception of motion may be supported, and consider the potential conflict that may arise between depth cues. We propose that the design of VE systems must centre on the perceptual-motor capabilities of the user, in the context of the task to be undertaken, and establish what isessential, desirableandoptimalin order to maximize the task gains, while minimizing the learning required to operate within three-dimensional interactive displays.},
author = {Wann, John and Mon-Williams, Mark},
doi = {10.1006/ijhc.1996.0035},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Wann, Mon-Williams/International Journal of Human-Computer Studies/Wann, Mon-Williams - 1996 - What does virtual reality NEED human factors issues in the design of three-dimensional computer environments.pdf:pdf},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {829--847},
title = {{What does virtual reality NEED?: human factors issues in the design of three-dimensional computer environments}},
url = {http://www.sciencedirect.com/science/article/pii/S107158199690035X},
volume = {44},
year = {1996}
}
@article{Whyte1999,
abstract = {Virtual reality (VR) packages offer good visualization capabilities but inadequate facilities for either internal data management or data exchange with other packages. The potential usefulness of VR packages for industrial and business applications is limited by their lack of support for the manipulation of specialist information. Their generic nature cannot retain the complex semantics and syntax of industrial information. Within the iterative process of building design and visualization, support is required for construction industry data, which is ordered in a complex and domain specific manner. Improved transfer of data from specialist building design tools to virtual reality has been investigated in previous research, but in this paper it is argued that data transfer is not enough. Virtual reality techniques need to become available within the specialist buildings design tools and alter the interface to such applications},
author = {Whyte, Jennifer and Bouchlaghem, Dino and Thorpe, Tony},
doi = {10.1109/IV.1999.781544},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Whyte, Bouchlaghem, Thorpe/Proceedings of the International Conference on Information Visualisation/Whyte, Bouchlaghem, Thorpe - 1999 - Visualization and information A building design perspective.pdf:pdf},
isbn = {0769502105},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
pages = {104--109},
title = {{Visualization and information: A building design perspective}},
volume = {1999-Janua},
year = {1999}
}
@inproceedings{Khundam2015a,
abstract = {Virtual reality (VR) has become a very popular technology in recent years, which used in the field of multimedia for various purposes. One of the applications that widely used for simulating physical presence in the real world is walk-through VR. In the walk-through VR system will generate simulation character or avatar for user which able to control movement, especially first person movement walk-through in VR with many input devices. In this paper, we present a human - computer interaction with the connection of Oculus Rift and Leap Motion new technological devices for VR. Oculus Rift is VR headset or head - mounted display devices that have a small display optic in front of each eye. Oculus Rift can track head movement and change view point follow it. Leap Motion is in - air controller that can track hand gesture of the user. The combination of them will make users feel like immerse to VR. Users can move avatar any way in VR by their hand interact through the system via these devices. We introduce a new interactive hand gesture system with palm normal for control steering develop by the game engine Unity3D applies synchronization of Oculus Rift and Leap Motion. Our design and development method will allow users to adjust moving speed follows the hand gesture and the range of the user's hand that make a smoothly moving with acceleration.},
author = {Khundam, Chaowanan},
booktitle = {2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
doi = {10.1109/JCSSE.2015.7219818},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Khundam/2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)/Khundam - 2015 - First person movement control with palm normal and hand gesture interaction in virtual reality.pdf:pdf},
isbn = {978-1-4799-1966-6},
keywords = {Avatars,Computers,Engines,Game Engine,Games,Head - Mounted Display,Headphones,Human - Computer Interaction,In - Air Controller,Leap Motion new technological devices,Oculus Rift,Three-dimensional displays,Tracking,Unity3D game engine,Virtual Reality,avatar,avatars,digital simulation,first person movement control,gesture recognition,hand gesture interaction,human computer interaction,human-computer interaction,motion control,multimedia,palm normal,physical presence simulation,simulation character,small display optic,virtual reality,walk-through VR},
month = {jul},
pages = {325--330},
publisher = {IEEE},
shorttitle = {Computer Science and Software Engineering (JCSSE),},
title = {{First person movement control with palm normal and hand gesture interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7219818},
year = {2015}
}
@article{Carey1998,
abstract = {VRML stands for Virtual Reality Modeling Language. Technically,$\backslash$nVRML is neither virtual reality nor a modeling language. Virtual reality$\backslash$ngenerally implies an immersive 3D experience, which typically requires a$\backslash$nhead mounted display (HMD) and 3D input devices, such as digital gloves.$\backslash$nVRML neither requires nor imposes immersion. Furthermore, a true$\backslash$nmodeling language would contain richer geometric modeling primitives and$\backslash$nmechanisms. VRML provides a bare minimum of geometric modeling features$\backslash$nbut contains numerous features unavailable in a modeling language. If$\backslash$nVRML is not virtual reality or a modeling language, what is it? This$\backslash$nquestion has several answers. At its core, VRML serves as a 3D$\backslash$ninterchange format. It defines most of the commonly used semantics found$\backslash$nin today's 3D applications such as hierarchical transformations, light$\backslash$nsources, viewpoints, geometry, animation, fog, material properties, and$\backslash$ntexture mapping. Here's a second answer to: what is VRML? It's a 3D$\backslash$nanalog to HTML. This means that VRML serves as a simple, multiplatform$\backslash$nlanguage for publishing 3D Web pages. The fact that some information,$\backslash$nincluding games, engineering models, scientific visualizations,$\backslash$neducational experiences, and architecture, can best be experienced in 3D$\backslash$nhas motivated this language. Typically, these types of projects require$\backslash$nintensive interaction, animation, and user participation and exploration$\backslash$nbeyond what a page, text, or image based format can handle. Another$\backslash$nanswer is that VRML provides the technology to integrate 3D, 2D, text,$\backslash$nand multimedia into a coherent model},
author = {Carey, R.},
doi = {10.1109/93.713310},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Carey/IEEE Multimedia/Carey - 1998 - The virtual reality modeling language explained.pdf:pdf},
isbn = {1070-986X},
issn = {1070-986X},
journal = {IEEE Multimedia},
pages = {84--93},
title = {{The virtual reality modeling language explained}},
volume = {5},
year = {1998}
}
@inproceedings{Kwon2015,
abstract = {While virtual reality has been researched in many ways for spatial and scientific visualizations, comparatively little has been explored for visualizations of more abstract kinds of data. In particular, stereoscopic and VR environments for graph visualization have only been applied as limited extensions to standard 2D techniques (e.g. using stereoscopy for highlighting). In this work, we explore a new, immersive approach for graph visualization, designed specifically for virtual reality environments.},
author = {Kwon, Oh Hyun and Muelder, Chris and Lee, Kyungwon and Ma, Kwan Liu},
booktitle = {IEEE Pacific Visualization Symposium},
doi = {10.1109/PACIFICVIS.2015.7156357},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Kwon et al/IEEE Pacific Visualization Symposium/Kwon et al. - 2015 - Spherical layout and rendering methods for immersive graph visualization.pdf:pdf},
isbn = {9781467368797},
issn = {21658773},
pages = {63--67},
title = {{Spherical layout and rendering methods for immersive graph visualization}},
volume = {2015-July},
year = {2015}
}
@article{Woodard2015,
author = {Woodard, Will and Sukittanon, Somsak},
doi = {10.1109/SECON.2015.7132929},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Woodard, Sukittanon/Unknown/Woodard, Sukittanon - 2015 - Interactive Virtual Building Walkthrough Using Oculus Rift and Microsoft Kinect.pdf:pdf},
isbn = {9781467373005},
pages = {5--7},
title = {{Interactive Virtual Building Walkthrough Using Oculus Rift and Microsoft Kinect}},
year = {2015}
}
@inproceedings{Celentano2002,
abstract = {We merge the Pictorial Computing Laboratory (PCL) approach to WIMP interaction with the Interaction Locus approach to structuring visual spaces as a step toward the definition of a rational methodology for the design of Virtual Reality interactive systems. The merging of the two points of view allows the refinement of the model of interaction of a user with a virtual environment and leads to the definition of "real" and "virtual" characteristic pattern.},
author = {Celentano, A. and Fogli, D. and Mussio, P. and Pittarello, F.},
booktitle = {Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments},
doi = {10.1109/HCC.2002.1046343},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Celentano et al/Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments/Celentano et al. - 2002 - Virtual reality interaction the characteristic pattern approach.pdf:pdf},
isbn = {0-7695-1644-0},
keywords = {Character generation,Design methodology,Educational programs,Human computer interaction,Interaction Locus approach,Interactive systems,Laboratories,Layout,Merging,Pictorial Computing Laboratory,Virtual environment,Virtual reality,WIMP interaction,real characteristic pattern,user interfaces,virtual characteristic pattern,virtual reality,virtual reality interactive system design,visual space structuring},
pages = {48--50},
publisher = {IEEE Comput. Soc},
shorttitle = {Human Centric Computing Languages and Environments},
title = {{Virtual reality interaction: the characteristic pattern approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1046343},
year = {2002}
}
@article{Myers1998,
abstract = {An abstract is not available.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Myers, Brad a.},
doi = {10.1145/274430.274436},
eprint = {1111.6189v1},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Myers/Interactions/Myers - 1998 - A brief history of human-computer interaction technology.pdf:pdf},
isbn = {1072-5520},
issn = {10725520},
journal = {Interactions},
pages = {44--54},
pmid = {20876008},
title = {{A brief history of human-computer interaction technology}},
volume = {5},
year = {1998}
}
@book{Creswell2014,
address = {Thousand Oaks, CA},
author = {Creswell, John W.},
edition = {4},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Creswell/Unknown/John W. Creswell-Research Design{\_} Qualitative, Quantitative, and Mixed Methods Approaches-SAGE Publications, Inc (2013).pdf:pdf},
isbn = {978-1-4522-2610-1},
pages = {342},
publisher = {Sage Publications, Inc.},
title = {{Research Design: Qualitative, Quantitative, and Mixed Methods Approaches}},
year = {2014}
}
@inproceedings{Valkov2012,
abstract = {Traditionally, interaction techniques for virtual reality applications are implemented in a proprietary way on specific target platforms, e. g., requiring specific hardware, physics or rendering libraries, which withholds reusability and portability. Though hardware abstraction layers for numerous devices are provided by multiple virtual reality libraries, they are usually tightly bound to a particular rendering environment. In this paper we introduce Viargo - a generic virtual reality interaction library, which serves as additional software layer that is independent from the application and its linked libraries, i. e., a once developed interaction technique, such as walking with a head-mounted display or multi-touch interaction, can be ported to different hard- or software environments with minimal code adaptation. We describe the underlying concepts and present examples on how to integrate Viargo in different graphics engines, thus extending proprietary graphics libraries with a few lines of code to easy-to-use virtual reality engines.},
author = {Valkov, Dimitar and Bolte, Benjamin and Bruder, Gerd and Steinicke, Frank},
booktitle = {2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)},
doi = {10.1109/SEARIS.2012.6231177},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Valkov et al/2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)/Valkov et al. - 2012 - Viargo - A generic virtual reality interaction library.pdf:pdf},
isbn = {978-1-4673-1248-6},
keywords = {Cameras,Engines,Hardware,Libraries,Rendering (computer graphics),Synchronization,Virtual reality library,abstraction layers,generic virtual reality interaction library,graphics engines,hardware abstraction layers,interaction metaphors,libraries,linked libraries,minimal code adaptation,proprietary graphics libraries,rendering (computer graphics),rendering environment,software layer,software portability,software reusability,viargo,virtual reality},
month = {mar},
pages = {23--28},
publisher = {IEEE},
shorttitle = {Software Engineering and Architectures for Realtim},
title = {{Viargo - A generic virtual reality interaction library}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6231177},
year = {2012}
}
@inproceedings{Kunzle2015,
abstract = {This paper describes how a Virtual Bank - a development and testing environment based on a purely synthetic test data base - has been established to address the challenge of protecting sensitive business and client data, while at the same time collaborating in application development and testing across country and jurisdiction borders.},
author = {Kunzle, Daniel and Worms, Carl},
booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
doi = {10.1109/ICST.2015.7102620},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Kunzle, Worms/2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)/Kunzle, Worms - 2015 - A Virtual Bank for Development and Testing.pdf:pdf},
isbn = {978-1-4799-7125-1},
keywords = {Business,Data privacy,Information technology,Production systems,Servers,Testing,Virtual Bank,application development,application testing,business data processing,client data protection,data protection,development environment,program testing,programming environments,purely synthetic test database,security of data,sensitive business protecting,testing environment},
month = {apr},
pages = {1--2},
publisher = {IEEE},
shorttitle = {Software Testing, Verification and Validation (ICS},
title = {{A Virtual Bank for Development and Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7102620},
year = {2015}
}
@article{Donalek2014,
abstract = {Effective data visualization is a key part of the discovery process in the era of “big data”. It is the bridge between the quantitative content of the data and human intuition, and thus an essential component of the scientific path from data into knowledge and understanding. Visualization is also essential in the data mining process, directing the choice of the applicable algorithms, and in helping to identify and remove bad data from the analysis. However, a high complexity or a high dimensionality of modern data sets represents a critical obstacle. How do we visualize interesting structures and patterns that may exist in hyper-dimensional data spaces? A better understanding of how we can perceive and interact with multidimensional information poses some deep questions in the field of cognition technology and human-computer interaction. To this effect, we are exploring the use of immersive virtual reality platforms for scientific data visualization, both as software and inexpensive commodity hardware. These potentially powerful and innovative tools for multi-dimensional data visualization can also provide an easy and natural path to a collaborative data visualization and exploration, where scientists can interact with their data and their colleagues in the same visual space. Immersion provides benefits beyond the traditional “desktop” visualization tools: it leads to a demonstrably better perception of a datascape geometry, more intuitive data understanding, and a better retention of the perceived relationships in the data.},
archivePrefix = {arXiv},
arxivId = {1410.7670},
author = {Donalek, Ciro and Djorgovski, S G and Cioc, Alex and Wang, Anwell and Zhang, Jerry and Lawler, Elizabeth and Yeh, Stacy and Mahabal, Ashish and Graham, Matthew and Drake, Andrew and Davidoff, Scott and Norris, Jeffrey S and Longo, Giuseppe},
doi = {10.1109/BigData.2014.7004282},
eprint = {1410.7670},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Donalek et al/IEEE International Conference on Big Data/Donalek et al. - 2014 - Immersive and Collaborative Data Visualization Using Virtual Reality Platforms.pdf:pdf},
isbn = {9781479956661},
journal = {IEEE International Conference on Big Data},
keywords = {and understanding of meaningful,astroinformatics,big data,big data science,data analysis,is not about data,it is about discovery,pattern recognition,that,the key point is,virtual reality,visualization},
pages = {609--614},
title = {{Immersive and Collaborative Data Visualization Using Virtual Reality Platforms}},
year = {2014}
}
@article{Dash2002,
abstract = {In this paper, we address the problem of automatic camera positioning and automatic camera path generation in the context of historical data visualization. After short description of the given data, we elaborate on the constraints for the positioning of a virtual camera in such a way that not only the projected area is maximized, but also the depth of the displayed scene. This is especially important when displaying terrain models, which do not provide good 3D impression when only the projected area is maximized. Based on this concept, we present a method for computing an optimal camera position for each instant of time. Since the explored data are not static, but change depending on the explored scene time, we also discuss a method for animation generation. In order to avoid sudden changes of the camera position, when the previous method is applied for each frame (point in time), we introduce pseudo-events in time, which expand the bounding box defined by the currently active events of interest. In particular, this technique allows events happening in a future point in time to be taken into account such that when this time becomes current, all events of interest are already within the current viewing frustum of the camera.},
author = {Dash, Puja},
doi = {10.1109/VISUAL.2002.1183826},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Dash/IEEE Visualization, 2002. VIS 2002/Dash - 2002 - A case study on automatic camera placement and motion for visualizing historical data.pdf:pdf},
isbn = {0-7803-7498-3},
issn = {0780374983},
journal = {IEEE Visualization, 2002. VIS 2002.},
keywords = {automatic camera control,automatic camera path and,data,fly control generator turned,historical,out to be,time-dependent data,very useful exploration props,visualization,visualization techniques},
number = {49},
pages = {545--548},
title = {{A case study on automatic camera placement and motion for visualizing historical data}},
year = {2002}
}
@article{Liao1999,
abstract = {Virtual banking is broadly defined in this paper as the provision of banking services via means other than traditional physical branches. Currently, virtual banking exists in the forms of ATM, phone banking, home banking and Internet banking. Understanding people's adoption intention of virtual banking can help financial institutions to formulate appropriate marketing strategies for new forms of banking. Theory of planned behavior (TPB) and innovation diffusion were used to study the adoption intention of virtual banking in a well-developed international financial city. The study finds that the relationships were found only partially explained by the TPB. Other results are interesting and useful for the strategic planning of IT in banking.},
author = {Liao, Shaoyi and Shao, Yuan Pu and Wang, Huaiqing and Chen, Ada},
doi = {10.1016/S0268-4012(98)00047-4},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Liao et al/International Journal of Information Management/Liao et al. - 1999 - The adoption of virtual banking an empirical study.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {banking,information technology,innovation diffusion,virtual banking},
number = {1},
pages = {63--74},
title = {{The adoption of virtual banking: an empirical study}},
volume = {19},
year = {1999}
}
@book{Rosson2002,
abstract = {You don't need to be convinced. You know that usability is key to the success of any interactive system-from commercial software to B2B Web sites to handheld devices. But you need skills to make usability part of your product development equation. How will you assess your users' needs and preferences? How will you design effective solutions that are grounded in users' current practices? How will you evaluate and refine these designs to ensure a quality product?Usability Engineering: Scenario-Based Development of Human-Computer Interaction is a radical departure from traditional books that emphasize theory and address experts. This book focuses on the realities of product development, showing how user interaction scenarios can make usability practices an integral part of interactive system development. As you'll learn, usability engineering is not the application of inflexible rules; it's a process of analysis, prototyping, and problem solving in which you evaluate tradeoffs, make reasoned decisions, and maximize the overall value of your product. * Written by prominent HCI educators who understand how to teach usability practices to students and professional developers.* Interleaves HCI theory and concepts with a running case study demonstrating their application. * Gradually elaborates the case study to introduce increasingly sophisticated usability engineering techniques.* Analyzes usability issues in realistic scenarios that describe existing or envisioned systems from the perspective of one or more users.* Emphasizes the real world of usability engineering-a world in which tradeoffs must be weighed and difficult decisions made to achieve desired results.* Includes a companion Web site which provides additional case studies in a multimedia format, along with a Java application for creating and editing scenarios. This site also provides instructors with sample syllabi, lecture slides and notes, in-class exercises, solutions to textbook exercises, additional project ideas, and links to other HCI resources.},
author = {Rosson, Mary Beth and Carroll, John Millar},
isbn = {1558607129},
pages = {422},
publisher = {Morgan Kaufmann},
title = {{Usability Engineering: Scenario-based Development of Human-computer Interaction}},
url = {https://books.google.com/books?hl=en{\&}lr={\&}id=sRPg0IYhYFYC{\&}pgis=1},
year = {2002}
}
@article{Ribarsky1994,
abstract = {Current virtual reality technologies have not yet crossed the threshold of usability. Not surprisingly, VR has so far shown more promise than practical applications. Yet the promise looks bright for fields such as data visualization and analysis. For such problems, VR offers a natural interface between human and computer that will simplify complicated manipulations of the data. It also provides an opportunity to rely on the interplay of combined senses rather than on a single or even dominant sense. Still, we cannot yet say whether VR is better than other visualization and analysis approaches for certain classes of data and, if so, by how much. The payoff will come not for those applications or tasks for which VR is merely better, even if significantly, but for those applications or tasks for which it offers some unique advantage unavailable otherwise. To answer these questions, we embarked on a multipronged program involving the Graphics, Visualization. and Usability (GVU) Center, the Office of Information Technology Scientific Visualization Lab. and other research groups at Georgia Tech. Integration is mandatory since these questions involve basic considerations: how immersive environments affect user interfaces and human-computer interactions; the ranges and capabilities of sensors; computer graphics and the VR optical system; and applications' needs. We describe some of our results},
author = {Ribarsky, W. and Bolter, J. and Bosch, a. Op Den and Teylingen, R. Van},
doi = {10.1109/38.250911},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Ribarsky et al/IEEE Computer Graphics and Applications/Ribarsky et al. - 1994 - Visualization and analysis using virtual reality.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
number = {1},
pages = {10--12},
title = {{Visualization and analysis using virtual reality}},
volume = {14},
year = {1994}
}
@inproceedings{Takala2014,
abstract = {Summary form only given. Recently a number of affordable game controllers have been adopted by virtual reality (VR) researchers [1][4]. We present a video1 of a VR demo called TurboTuscany, where we employ such controllers; our demo combines a Kinect controlled full body avatar with Oculus Rift head-mounted-display [2]. We implemented three positional head tracking schemes that use Kinect, Razer Hydra, and PlayStation (PS) Move controllers. In the demo the Kinect tracked avatar can be used to climb ladders, play with soccer balls, and otherwise move or interact with physically simulated objects. PS Move or Razer Hydra controller is used to control locomotion, and for selecting and manipulating objects. Our subjective experience is that the best head tracking immersion is achieved by using Kinect together with PS Move, as the latter is more accurate and responsive while having a large tracking volume. We also noticed that Oculus Rift's orientation tracking has less latency than any of the positional trackers that we used, while Razer Hydra has less latency than PS Move, and Kinect has the largest latency. Besides positional tracking, our demo uses these three trackers to correct the yaw drift of Oculus Rift. TurboTuscany was developed by using our RUIS toolkit, which is a software platform for VR application development [3]. The demo and RUIS toolkit can be downloaded online2.},
author = {Takala, Tuukka M. and Matveinen, Mikael},
booktitle = {2014 IEEE Virtual Reality (VR)},
doi = {10.1109/VR.2014.6802099},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Takala, Matveinen/2014 IEEE Virtual Reality (VR)/Takala, Matveinen - 2014 - Full body interaction in virtual reality with affordable hardware.pdf:pdf},
isbn = {978-1-4799-2871-2},
keywords = {Avatars,Games,Hardware,Kinect controlled full body avatar,Media,Oculus Rift head-mounted-display,PS Move controller,PlayStation Move controller,RUIS toolkit,Razer Hydra controller,Tracking,TurboTuscany,VR application development,VR demo,avatars,computer games,game controllers,helmet mounted displays,ladders,locomotion control,motion control,object manipulation,object selection,object tracking,physically simulated objects,positional head tracking schemes,soccer balls,software platform,virtual reality},
month = {mar},
pages = {157--157},
publisher = {IEEE},
shorttitle = {Virtual Reality (VR), 2014 iEEE},
title = {{Full body interaction in virtual reality with affordable hardware}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6802099},
year = {2014}
}
@article{Sarathy2000,
abstract = {Major advances in high performance computing software and hardware$\backslash$nhave made it possible for designers and analysts to obtain detailed$\backslash$ninformation about the behavior of complex systems. However, this has$\backslash$nlead to a proliferation of vast amounts of data which is beyond the$\backslash$nability of humans to easily comprehend using traditional visualization$\backslash$nmethods. The method presented combines emerging visualization tools with$\backslash$ndata filtering and data mining techniques. This method uses virtual$\backslash$nreality (VR) coupled with multimedia techniques to display information$\backslash$nwithin an environment that allows non-expert users to understand and$\backslash$ninterpret the data. A prototype visualization tool was developed under a$\backslash$nNASA SBIR Phase II effort. This paper builds on the results of this work$\backslash$nand suggests a visualization framework that can be used to examine,$\backslash$ncomprehend and interpret results in any complex data set, particularly$\backslash$nthose used in support of decision making activities},
author = {Sarathy, S. and Shujaee, K. and Cannon, K.},
doi = {10.1109/ITCC.2000.844280},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Sarathy, Shujaee, Cannon/Proceedings International Conference on Information Technology Coding and Computing (Cat. No.PR00540)/Sarathy, Shujaee, Cannon - 2000 - Visualization of large complex datasets using virtual reality.pdf:pdf},
isbn = {0-7695-0540-6},
journal = {Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540)},
pages = {1--5},
title = {{Visualization of large complex datasets using virtual reality}},
year = {2000}
}
@inproceedings{Latham1997,
abstract = {Issues related to the design of virtual reality systems are discussed in the context of the development effort for a virtual cockpit. Subsystems provide visual imagery, hand and head tracking, control logic and force feedback. The force feedback subsystem uses robotic positioning to place an assortment of knobs and switches into position to be touched: the user's hand trajectory is extrapolated and the correct type of control is placed just in time to be actuated. Discussion focuses on selecting among alternative system elements and configurations in arriving at an overall systems design.},
author = {Latham, R.},
booktitle = {Proceedings IEEE COMPCON 97. Digest of Papers},
doi = {10.1109/CMPCON.1997.584738},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Latham/Proceedings IEEE COMPCON 97. Digest of Papers/Latham - 1997 - Designing virtual reality systems a case study of a system with humanrobotic interaction.pdf:pdf},
isbn = {0-8186-7804-6},
issn = {1063-6390},
keywords = {Aircraft manufacture,Computational modeling,Computer aided software engineering,Computer displays,Force control,Human robot interaction,Image generation,Instruments,Switches,Virtual reality,actuation,aircraft computers,case study,control logic,feedback,force feedback,hand tracking,hand trajectory extrapolation,head tracking,human/robotic interaction,interactive devices,knobs,man-machine systems,robotic positioning,robots,subsystems,switches,system configurations,system elements,tracking,virtual cockpit,virtual reality,virtual reality systems design,visual imagery},
pages = {302--307},
publisher = {IEEE Comput. Soc. Press},
shorttitle = {Compcon '97. Proceedings, IEEE},
title = {{Designing virtual reality systems: a case study of a system with human/robotic interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=584738},
year = {1997}
}
@inproceedings{Muller1998,
abstract = {A system for the visualization of three-dimensional anatomical data, derived from magnetic resonance imaging (MRI) or computed tomography (CT), enables the physician to navigate through and interact with the patient's 3D scans in a virtual environment. This paper presents the multimodal human-machine interaction focusing the speech input. For the concerned task, a speech understanding front-end using a special kind of semantic decoder was successfully adopted. Now, the navigation as well as certain parameters and functions can be directly accessed by spoken commands. Using the implemented interaction modalities, the speed and efficiency of the diagnosis could be considerably improved},
author = {Muller, J. and Krapichler, C. and {Hans Englmeier}, K. and Lang, M.},
booktitle = {Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
doi = {10.1109/ICASSP.1998.679701},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Muller et al/Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)/Muller et al. - 1998 - Speech interaction in virtual reality.pdf:pdf},
isbn = {0-7803-4428-6},
issn = {1520-6149},
keywords = {CT,Computed tomography,Data visualization,Decoding,Focusing,MRI,Magnetic resonance imaging,Man machine systems,Navigation,Speech,Virtual environment,Virtual reality,anatomical data visualization,biomedical NMR,computed tomography,computerised tomography,data visualisation,decoding,efficiency,magnetic resonance imaging,multimodal human-machine interaction,natural language interfaces,navigation,patient 3D scans,patient diagnosis,semantic decoder,speech input,speech interaction,speech processing,speech understanding front-end,speed,spoken commands,virtual environment,virtual reality},
pages = {3757--3760},
publisher = {IEEE},
shorttitle = {Acoustics, Speech and Signal Processing, 1998. Pro},
title = {{Speech interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=679701},
volume = {6},
year = {1998}
}
@article{Sun2011,
abstract = {The study constructs joyful Web 3D virtual situational learning materials with the perspectives of learners, and takes Tainan Confucian Temple as an example to allow the learners to learn and experience freely in virtual reality. The joyful learning environment is presented in the virtual situation through vivid text, sound, a guided picture tour, and a game-like learning mechanism. Different from the passive “knowledge giving model” in the past virtual situational learning system, the “joyful learning component” is integrated into the virtual situation to change knowledge imparting from “passive” to “active” to effectively enhance the learning motivation of learners and improve their learning effectiveness. Finally, grade 5 students are applied as the experimental subjects in the study analysis focusing on the satisfaction of learning system application and the significance difference of the learning result before and after the system is applied. The study result shows that the application of a joyful virtual situation can indeed achieve the same effectiveness of on- site experimental learning.},
author = {Sun, Koun-Tem and Chan, Hsin-Te and Yin, Tai-lin},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Sun, Chan, Yin/The 7th International Conference on Digital Content, Multimedia Technology and its Applications/Sun, Chan, Yin - 2011 - A case study on building Web3D virtual reality and its applications to joyful learning.pdf:pdf},
isbn = {9788988678466},
journal = {The 7th International Conference on Digital Content, Multimedia Technology and its Applications},
keywords = {Electronic learning,Games,Learning systems,Solid modeling,Tainan Confucian Temple,Three dimensional displays,Web3D virtual reality building,computer aided instruction,e-learning,game-like learning mechanism,joyful Web 3D virtual situational learning materia,joyful learning component,knowledge giving model,learning,on-site experimental learning,situational teaching,virtual reality,virtual situational learning system},
mendeley-tags = {e-learning,learning,situational teaching},
month = {aug},
pages = {49--54},
title = {{A case study on building Web3D virtual reality and its applications to joyful learning}},
url = {http://ieeexplore.ieee.org/ielx5/6008798/6016618/06016630.pdf?tp={\&}arnumber=6016630{\&}isnumber=6016618},
year = {2011}
}
@inproceedings{Shujun2011,
abstract = {Mixed reality (MR) is a further research hotspot with the development of virtual reality (VR). Seamless fusion and real-time interaction between virtual environment and real users or objects are two most important problems urgent to be solved for a MR system. In this paper an engine of virtual reality mixing environment E-VRME is proposed based on real-time modeling and interaction and three applications are demonstrated. The engine runs on our self-built hardware platform DreamWorld and has three modules. Graphics module is designed for VE rendering, modeling module for 3D reconstruction and V-R interaction module for collision detection and feedback. An octree-based visual hull modeling method is used for constructing the mesh models of all the users from their multi-view images. Then, marching cubes algorithm is applied for triangulation and texture mapping is carried out. E-VRME integrates virtual and real information into a seamless unit and it supports any kinds of real-time MR applications. Experimental results and three different application systems proved its usefulness and effectiveness.},
author = {Shujun, Zhang},
booktitle = {2011 IEEE International Symposium on VR Innovation},
doi = {10.1109/ISVRI.2011.5759621},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Shujun/2011 IEEE International Symposium on VR Innovation/Shujun - 2011 - An engine of virtual reality mixing environment based on real-time modeling and interaction.pdf:pdf},
isbn = {978-1-4577-0055-2},
keywords = {Cameras,DreamWorld,E-VRME,Engines,Image reconstruction,MR,Mixed reality,Real time systems,Solid modeling,VE rendering,Virtual reality,Visualization,collision detection,computer graphics,engine of virtual reality mixing environment,graphics module,mixed reality,real time reconstruction,real-time interaction,real-time modeling,real-time systems,tele-immersion,virtual reality,virtual-reality interaction},
month = {mar},
pages = {155--159},
publisher = {IEEE},
shorttitle = {VR Innovation (ISVRI), 2011 IEEE International Sym},
title = {{An engine of virtual reality mixing environment based on real-time modeling and interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5759621},
year = {2011}
}
@article{Forsberg1997,
abstract = {Jot is a novel research interface for virtual reality modeling. This system seamlessly integrates and applies a variety of virtual and physical tools, each customized for specific tasks. The Jot interface not only moves smoothly from one tool to another but also physically and cognitively matches individual tools to the tasks they perform. In particular, we exploit the notion that gestural interaction is more direct, in many cases, than traditional widget based interaction. We also respect the time tested observation that some operations-even conceptually three dimensional ones-are better performed with 1D or 2D input devices, whereas other operations are more naturally performed using stereoscopic views, higher DOF input devices, or both. Ultimately we strive for a 3D modeling system with an interface as transparent as the interaction afforded by a pencil and a sheet of paper. For example, the system should facilitate the tasks of drawing and erasing and provide an easy transition between the two. Jot emerged from our previous work on a mouse based system, called Sketch, for gesturally creating imprecise 3D models. Jot extends Sketch's functionality to a wider spectrum of modeling, from concept design to detailed feature based parametric parts. Jot also extends the interaction in Sketch to better support individual modeling tasks. We extended Sketch's gestural framework to integrate interface components ranging from traditional desktop interface widgets to context sensitive gestures to direct manipulation techniques originally designed for immersive VR},
author = {Forsberg, A.S. and LaViola, J.J. and Markosian, L. and Zeleznik, R.C.},
doi = {10.1109/38.626956},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Forsberg et al/IEEE Computer Graphics and Applications/Forsberg et al. - 1997 - Seamless interaction in virtual reality.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
keywords = {3D modeling system,CAD,Geometry,Graphics,Java,Jot interface,Sketch,Surface fitting,Switches,Testing,Topology,Virtual reality,Web sites,Wheels,cognitive matching,concept design,context sensitive gestures,design engineering,desktop interface widgets,detailed feature based parametric parts,direct manipulation techniques,drawing,engineering graphics,erasing,gestural framework,gestural interaction,graphical user interfaces,immersive VR,imprecise 3D models,individual modeling tasks,interactive systems,mouse based system,novel research interface,seamless interaction,stereoscopic views,virtual reality,virtual reality modeling,widget based interaction},
number = {6},
pages = {6--9},
shorttitle = {IEEE Computer Graphics and Applications},
title = {{Seamless interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=626956},
volume = {17},
year = {1997}
}
@inproceedings{Pfeiffer2008,
abstract = {Interaction in conversational interfaces strongly relies on the system's capability to interpret the user's references to objects via deictic expressions. Deictic gestures, especially pointing gestures, provide a powerful way of referring to objects and places, e.g., when communicating with an embodied conversational agent in a virtual reality environment. We highlight results drawn from a study on pointing and draw conclusions for the implementation of pointing-based conversational interactions in partly immersive virtual reality.},
author = {Pfeiffer, Thies and Latoschik, Marc E. and Wachsmuth, Ipke},
booktitle = {2008 IEEE Virtual Reality Conference},
doi = {10.1109/VR.2008.4480801},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Pfeiffer, Latoschik, Wachsmuth/2008 IEEE Virtual Reality Conference/Pfeiffer, Latoschik, Wachsmuth - 2008 - Conversational Pointing Gestures for Virtual Reality Interaction Implications from an Empirical.pdf:pdf},
isbn = {978-1-4244-1971-5},
keywords = {Collaborative work,Computer graphics,Context modeling,Data mining,Games,H.5.2 [Information Interfaces and Presentation]: U,Humans,I.3.6 [Computer Graphics]: Methodology and Techniq,Object detection,Shape,Tracking,Virtual reality,conversational interfaces,conversational pointing gestures,deictic expressions,deictic gestures,embodied conversational agent,virtual reality,virtual reality interaction},
pages = {281--282},
publisher = {IEEE},
shorttitle = {Virtual Reality Conference, 2008. VR '08. IEEE},
title = {{Conversational Pointing Gestures for Virtual Reality Interaction: Implications from an Empirical Study}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4480801},
year = {2008}
}
@inproceedings{Hentschel2009,
abstract = {The analysis of time-dependent simulation data is a demanding task, both in terms of computing power and time. Interactive analysis using multiple linked views has been shown to be one possible solution to this problem. However, there are two significant short-comings when limited to a standard desktop-based setup: first, complex spatial relationships are hard to understand using only 2D projections of the data. Second, the size of today's simulation runs is too large to be handled even by powerful workstations. We describe a system for the interactive analysis of large, time-dependent data in virtual environments. Based on the techniques of multiple linked views and brushing, our approach allows the user to quickly formulate, visualize and assess hypotheses about the data. To enable an interactive exploration even in the face of multi-gigabyte data sets, we distribute the workload to a multi-processor parallel machine and a rendering client.},
author = {Hentschel, Bernd and Wolter, Marc and Kuhlen, Torsten},
booktitle = {Proceedings - IEEE Virtual Reality},
doi = {10.1109/VR.2009.4811041},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Hentschel, Wolter, Kuhlen/Proceedings - IEEE Virtual Reality/Hentschel, Wolter, Kuhlen - 2009 - Virtual reality-based multi-view visualization of time-dependent simulation data.pdf:pdf},
isbn = {9781424439430},
issn = {1087-8270},
keywords = {I.3.6 [computer graphics]: Interaction techniques,Virtual reality I.6.6 [Simulation and Modelling]:S,[I.3.7]: Computer graphics},
pages = {253--254},
title = {{Virtual reality-based multi-view visualization of time-dependent simulation data}},
year = {2009}
}
@book{Hevner2010,
address = {Boston, MA},
author = {Hevner, Alan and Chatterjee, Samir},
doi = {10.1007/978-1-4419-5653-8},
isbn = {978-1-4419-5652-1},
keywords = {Design Research},
mendeley-tags = {Design Research},
pages = {320},
publisher = {Springer US},
series = {Integrated Series in Information Systems},
title = {{Design Research in Information Systems}},
url = {http://link.springer.com/10.1007/978-1-4419-5653-8},
volume = {22},
year = {2010}
}
@article{Laha2012,
abstract = {Volume visualization has been widely used for decades for analyzing datasets ranging from 3D medical images to seismic data to paleontological data. Many have proposed using immersive virtual reality (VR) systems to view volume visualizations, and there is anecdotal evidence of the benefits of VR for this purpose. However, there has been very little empirical research exploring the effects of higher levels of immersion for volume visualization, and it is not known how various components of immersion influence the effectiveness of visualization in VR. We conducted a controlled experiment in which we studied the independent and combined effects of three components of immersion (head tracking, field of regard, and stereoscopic rendering) on the effectiveness of visualization tasks with two x-ray microscopic computed tomography datasets. We report significant benefits of analyzing volume data in an environment involving those components of immersion. We find that the benefits do not necessarily require all three components simultaneously, and that the components have variable influence on different task categories. The results of our study improve our understanding of the effects of immersion on perceived and actual task performance, and provide guidance on the choice of display systems to designers seeking to maximize the effectiveness of volume visualization applications.},
author = {Laha, Bireswar and Sensharma, Kriti and Schiffbauer, James D. and Bowman, Doug A.},
doi = {10.1109/TVCG.2012.42},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Laha et al/IEEE Transactions on Visualization and Computer Graphics/Laha et al. - 2012 - Effects of Immersion on Visual Analysis of Volume Data.pdf:pdf},
isbn = {1077-2626 VO - 18},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {3D visualization,CAVE,Immersion,data analysis,micro-CT,virtual environments,virtual reality,volume visualization},
number = {4},
pages = {597--606},
pmid = {22402687},
title = {{Effects of immersion on visual analysis of volume data}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6165141},
volume = {18},
year = {2012}
}
@article{Burlutskiy2014a,
abstract = {Complexity and scale of modern data is at its highest level but its temporal properties are often neglected. As a result, it is often hard for a user to make an informed decision about its time related characteristics. However, an aesthetic and efficient visualization can mitigate this drawback of data representation. For example, an informative graphical visualization based on user's interaction with a computer interface can dramatically improve user experience with temporal data. In this paper, I propose such visualization of temporal data for reasoning. I developed a temporal model supporting different temporal entities for this data. These include timestamps, intervals, different time granularity and uncertainty of time. I proposed a multimodal visualization based on this abstract time model so a user will have the functionality to reason on temporal properties of visualized data from different points of view.},
author = {Burlutskiy, Nikolay and Petridis, Miltos and Fish, Andrew and Ali, Nour},
doi = {10.1109/VLHCC.2014.6883044},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Burlutskiy et al/Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VLHCC/Burlutskiy et al. - 2014 - Enabling the visualization for reasoning about temporal data.pdf:pdf},
isbn = {9781479940356},
issn = {19436106},
journal = {Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC},
pages = {179--180},
title = {{Enabling the visualization for reasoning about temporal data}},
year = {2014}
}
@article{Li2005a,
abstract = {Virtual banking is broadly defined in this paper as the provision of banking services via means other than that of traditional physical branches. Currently, virtual banking exists in the forms of ATM, phone banking, home banking and Internet banking. Understanding people's adoption intention of virtual banking can help financial institutions formulate appropriate marketing strategies for new forms of banking. This paper examines the current trends in the Internet revolution that have set in motion in the Chinese banking sector, and reports on an empirical research carried out in China to study the customers' preference for virtual banking and the factors which they consider influence the adoption of virtual banking.},
author = {Li, Zheng and Zhong, Yonghong},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Li, Zhong/Chinese Business Review/Li, Zhong - 2005 - The Adoption of Virtual Banking in China An Empirical Study.pdf:pdf},
journal = {Chinese Business Review},
keywords = {Information technology,commercial bank,virtual banking},
number = {3},
pages = {75--78},
title = {{The Adoption of Virtual Banking in China: An Empirical Study}},
url = {http://tpprofiuba.googlecode.com/svn-history/r195/trunk/Material/e-Banking/17-The Adoption of Virtual Banking in.pdf},
volume = {1},
year = {2005}
}
@article{Sun2011,
abstract = {The study constructs joyful Web 3D virtual situational learning materials with the perspectives of learners, and takes Tainan Confucian Temple as an example to allow the learners to learn and experience freely in virtual reality. The joyful learning environment is presented in the virtual situation through vivid text, sound, a guided picture tour, and a game-like learning mechanism. Different from the passive “knowledge giving model” in the past virtual situational learning system, the “joyful learning component” is integrated into the virtual situation to change knowledge imparting from “passive” to “active” to effectively enhance the learning motivation of learners and improve their learning effectiveness. Finally, grade 5 students are applied as the experimental subjects in the study analysis focusing on the satisfaction of learning system application and the significance difference of the learning result before and after the system is applied. The study result shows that the application of a joyful virtual situation can indeed achieve the same effectiveness of on- site experimental learning.},
author = {Sun, Koun-Tem and Chan, Hsin-Te and Yin, Tai-lin},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Sun, Chan, Yin/The 7th International Conference on Digital Content, Multimedia Technology and its Applications/Sun, Chan, Yin - 2011 - A case study on building Web3D virtual reality and its applications to joyful learning.pdf:pdf},
isbn = {9788988678466},
journal = {The 7th International Conference on Digital Content, Multimedia Technology and its Applications},
keywords = {Electronic learning,Games,Learning systems,Solid modeling,Tainan Confucian Temple,Three dimensional displays,Web3D virtual reality building,computer aided instruction,e-learning,game-like learning mechanism,joyful Web 3D virtual situational learning materia,joyful learning component,knowledge giving model,learning,on-site experimental learning,situational teaching,virtual reality,virtual situational learning system},
mendeley-tags = {e-learning,learning,situational teaching},
month = {aug},
pages = {49--54},
title = {{A case study on building Web3D virtual reality and its applications to joyful learning}},
url = {http://ieeexplore.ieee.org/ielx5/6008798/6016618/06016630.pdf?tp={\&}arnumber=6016630{\&}isnumber=6016618},
year = {2011}
}
@inproceedings{Chun2015,
abstract = {The computers nowadays are powerful enough to make the virtual reality technology more practical. Virtual reality is expected to have a bright future due to the rise of several virtual reality head mounted device such as low cost Google Cardboard, Samsung Gear VR, Oculus, HTC Vive and many others. Since virtual reality had been growing fast in this few years thus it is necessary to explore new approaches for user to interact with the virtual reality more naturally. It is an important research in HCI to make the interactions with computers to be as natural as the interaction between humans. One of the approaches is to allow user to interact with the virtual reality through gesture and speech input. This paper presents a virtual reality environment with multimodal interaction technique. It allows user to interact with the virtual reality system with the static and stroke hand gesture along with speech. This multimodal interaction technique is able to perform few functions such as select, move, scale, rotate, copy, mirror, delete, check the shape, check and change the colour of an object.},
author = {Chun, Lam Meng and Arshad, Haslina and Piumsomboon, Thammathip and Billinghurst, Mark},
booktitle = {2015 International Conference on Electrical Engineering and Informatics (ICEEI)},
doi = {10.1109/ICEEI.2015.7352470},
file = {:Users/klingo/Dropbox/Studium/MENDELEY/File Organizer/Chun et al/2015 International Conference on Electrical Engineering and Informatics (ICEEI)/Chun et al. - 2015 - A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment.pdf:pdf},
isbn = {9781467373197},
keywords = {Virtual Reality,gesture,hand gesture and speech,human computer interaction,interaction,multimodal,natural interaction,new,speech,speech recognition},
mendeley-tags = {Virtual Reality,gesture,multimodal,new,speech,speech recognition},
month = {aug},
pages = {59--64},
publisher = {IEEE},
title = {{A Combination of Static and Stroke Gesture with Speech for Multimodal Interaction in a Virtual Environment}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=7352470},
year = {2015}
}
@article{Anthes,
abstract = {In the past three years, the so-called second wave of Virtual Reality (VR) has brought us a vast amount of new dis- plays and input devices. Not only new hardware has entered the consumer market providing affordable pricing models but also completely new technologies are being designed and developed. Additionally new concepts for handling existing problems on the hardware and software side of the VR technology are constantly being introduced. This software and hardware development is mainly lead by enthusiasts interested in the domain of VR opposed to the established scientific community, which already partially makes use of the newly available technology. Besides Head-Mounted Displays (HMDs), either cable-based or mobile, other devices like haptics devices, controllers, vests, omnidirectional tread- mills, tracking technologies, as well as optical scanners for gesture-based interaction are gaining importance in the field of commodity VR. Most of these technologies are already precise and robust enough to be used for professional operation and scientific experiments. The topics discussed are the common issues with the new tech- nologies including the approaches to solve them as for example motion-to-photon latency, barrel distortion, and low-persistence displays. Additionally an in-depth analysis of the available solutions expected to hit the market is provided. A taxonomy categorising the current developments with the chosen imple- mentation approaches will be given. The paper analyses the state of technological advancements in the field and provides an extensive overview on the current development considering the upcoming devices and the advancements from the software side.},
author = {Anthes, Christoph and Garc{\'{i}}a-Hern{\'{a}}ndez, Rub{\'{e}}n Jes{\'{u}}s and Kranzlm{\"{u}}ller, Markus and {Wiedemann Dieter}},
file = {::},
journal = {2016 IEEE Aerospace Conference, At Big Sky, Montana, United States},
title = {{State of the Art of Virtual Reality Technology}}
}
@inproceedings{Khundam2015,
abstract = {Virtual reality (VR) has become a very popular technology in recent years, which used in the field of multimedia for various purposes. One of the applications that widely used for simulating physical presence in the real world is walk-through VR. In the walk-through VR system will generate simulation character or avatar for user which able to control movement, especially first person movement walk-through in VR with many input devices. In this paper, we present a human - computer interaction with the connection of Oculus Rift and Leap Motion new technological devices for VR. Oculus Rift is VR headset or head - mounted display devices that have a small display optic in front of each eye. Oculus Rift can track head movement and change view point follow it. Leap Motion is in - air controller that can track hand gesture of the user. The combination of them will make users feel like immerse to VR. Users can move avatar any way in VR by their hand interact through the system via these devices. We introduce a new interactive hand gesture system with palm normal for control steering develop by the game engine Unity3D applies synchronization of Oculus Rift and Leap Motion. Our design and development method will allow users to adjust moving speed follows the hand gesture and the range of the user's hand that make a smoothly moving with acceleration.},
author = {Khundam, Chaowanan},
booktitle = {2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
doi = {10.1109/JCSSE.2015.7219818},
isbn = {978-1-4799-1966-6},
keywords = {Avatars,Computers,Engines,Game Engine,Games,Head - Mounted Display,Headphones,Human - Computer Interaction,In - Air Controller,Leap Motion new technological devices,Oculus Rift,Three-dimensional displays,Tracking,Unity3D game engine,Virtual Reality,avatar,avatars,digital simulation,first person movement control,gesture recognition,hand gesture interaction,human computer interaction,human-computer interaction,motion control,multimedia,palm normal,physical presence simulation,simulation character,small display optic,virtual reality,walk-through VR},
month = {jul},
pages = {325--330},
publisher = {IEEE},
shorttitle = {Computer Science and Software Engineering (JCSSE),},
title = {{First person movement control with palm normal and hand gesture interaction in virtual reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7219818},
year = {2015}
}
